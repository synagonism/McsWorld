<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Mcs.techInfo-(1-13-0.2023-04-09) information-technology</title>
  <meta name="keywords" content="information-technology, techInfo, ModelConceptSensorial, McsHitp, Synagonism">
  <link rel="stylesheet" href="../Mcsmgr/mHitp.css">
</head>

<body>
<header id="idHeader">
  <p></p>
  <h1 id="idHeaderH1">information-technology
    <br>senso-concept-Mcs (techInfo)
    </h1>
  <p id="idHeadercrd">McsHitp-creation:: {2019-12-28},
    <a class="clsHide" href="#idHeadercrd"></a></p>
</header>

<section id="idOverview">
  <h1 id="idOverviewH1">overview of techInfo
    <a class="clsHide" href="#idOverviewH1"></a></h1>
  <p id="idDescription">description::
    <br>· info-tech is <a class="clsPreview" href="../dirTch/McsTch000002.last.html#idTchHmn">human-technology</a> that manages <a class="clsPreview" href="../dirLag/McsLag000003.last.html#idInfHmnBrn">brain-info</a>.
    <a class="clsHide" href="#idDescription"></a></p>
  <p id="idName">name::
    <br>* McsEngl.McsTchInf000002.last.html//dirTchInf//dirMcs!⇒techInfo,
    <br>* McsEngl.dirMcs/dirTchInf/McsTchInf000002.last.html!⇒techInfo,
    <br>* McsEngl.IT'(info-tech)!⇒techInfo,
    <br>* McsEngl.techInfo,
    <br>* McsEngl.info-tech!⇒techInfo,
    <br>* McsEngl.information-technology!⇒techInfo,
    <br>* McsEngl.infotech!⇒techInfo,
    <br>* McsEngl.tchInf!⇒techInfo,
    <br>* McsEngl.techInfo'(McsTchInf000002)!⇒techInfo,
    <br>* McsEngl.techInfo'(information-technology)!⇒techInfo,
    <br>====== langoSinago:
    <br>* McsSngo.teko-info!=techInfo,
    <br>====== langoGreek:
    <br>* McsElln.πληροφορίας-τεχνολογία!=techInfo,
    <a class="clsHide" href="#idName"></a></p>
</section>

<section id="idTchInfatt001">
  <h1 id="idTchInfatt001H1">01_evaluation of techInfo
    <a class="clsHide" href="#idTchInfatt001H1"></a></h1>
  <p id="idTchInfatt001dsn">description::
    <br>·
    <a class="clsHide" href="#idTchInfatt001dsn"></a></p>
  <p id="idTchInfatt001nam">name::
    <br>* McsEngl.techInfo'01_evaluation,
    <br>* McsEngl.techInfo'att001-evaluation,
    <br>* McsEngl.techInfo'evaluation,
    <a class="clsHide" href="#idTchInfatt001nam"></a></p>
</section>

<section id="idTchInfatt002">
  <h1 id="idTchInfatt002H1">02_human of techInfo
    <a class="clsHide" href="#idTchInfatt002H1"></a></h1>
  <p id="idTchInfatt002dsn">description::
    <br>· any <a class="clsPreview" href="../dirHmn/McsHmn000002.last.html#idOverview">human</a> related with techInfo.
    <a class="clsHide" href="#idTchInfatt002dsn"></a></p>
  <p id="idTchInfatt002nam">name::
    <br>* McsEngl.techInfo'02_human,
    <br>* McsEngl.techInfo'att002-human,
    <br>* McsEngl.techInfo'human,
    <a class="clsHide" href="#idTchInfatt002nam"></a></p>
  <p id="idTchInfatt002str">specific-tree-of-techInfo'human::
    <br>* user,
    <br>* worker,
    <br>* programer,
    <br>* hacker,
    <a class="clsHide" href="#idTchInfatt002str"></a></p>
</section>

<section id="idTchInfatt004">
  <h1 id="idTchInfatt004H1">03_organization (<a class="clsPreview" href="McsStn000015.last.html#idOznPdn003">link</a>) of techInfo
    <a class="clsHide" href="#idTchInfatt004H1"></a></h1>
</section>

<section id="idTchInfatt003">
  <h1 id="idTchInfatt003H1">04_law of techInfo
    <a class="clsHide" href="#idTchInfatt003H1"></a></h1>
  <p id="idTchInfatt003dsn">description::
    <br>· law related to techInfo.
    <a class="clsHide" href="#idTchInfatt003dsn"></a></p>
  <p id="idTchInfatt003nam">name::
    <br>* McsEngl.law.techInfo,
    <br>* McsEngl.techInfo'04_law,
    <br>* McsEngl.techInfo'att003-law,
    <br>* McsEngl.techInfo'law,
    <a class="clsHide" href="#idTchInfatt003nam"></a></p>
</section>

<section id="idTchInfivmt">
  <h1 id="idTchInfivmtH1">05_investment of techInfo
    <a class="clsHide" href="#idTchInfivmtH1"></a></h1>
  <p id="idTchInfivmtdsn">description::
    <br>·
    <a class="clsHide" href="#idTchInfivmtdsn"></a></p>
  <p id="idTchInfivmtnam">name::
    <br>* McsEngl.techInfo'05_investment,
    <br>* McsEngl.techInfo'investment,
    <a class="clsHide" href="#idTchInfivmtnam"></a></p>
</section>

<section id="idTchInfrscF">
  <h1 id="idTchInfrscFH1">info-resource of techInfo
    <a class="clsHide" href="#idTchInfrscFH1"></a></h1>
  <p id="idTchInfrscnam">name::
    <br>* McsEngl.techInfo'Infrsc,
    <a class="clsHide" href="#idTchInfrscnam"></a></p>
  <p id="idTchInfrscwpa">addressWpg::
    <br>* http://reports.weforum.org/global-information-technology-report-2016/
    <br>* http://www.gartner.com/it-glossary/
    <br>* http://www.techterms.com/
    <a class="clsHide" href="#idTchInfrscwpa"></a></p>
</section>

<section id="idTchInfdngF">
  <h1 id="idTchInfdngFH1">DOING of techInfo
    <a class="clsHide" href="#idTchInfdngFH1"></a></h1>
  <p id="idTchInfdngFdsn">description::
    <br>* processing,
    <br>* communicating,
    <br>* storing,
    <a class="clsHide" href="#idTchInfdngFdsn"></a></p>
  <p id="idTchInfdngFnam">name::
    <br>* McsEngl.techInfo'doing,
    <a class="clsHide" href="#idTchInfdngFnam"></a></p>
</section>

<section id="idTchInfevgF">
  <h1 id="idTchInfevgFH1">evoluting of techInfo
    <a class="clsHide" href="#idTchInfevgFH1"></a></h1>
  <p id="idTchInfevgnam">name::
    <br>* McsEngl.techInfo'evoluting,
    <a class="clsHide" href="#idTchInfevgnam"></a></p>
  <p id="idTchInfevgFwpa">addressWpg::
    <br>* Hellenic IT Museum: https://elmp.gr/,
    <a class="clsHide" href="#idTchInfevgFwpa"></a></p>
  <p id="idTchInfevg20191228">{2019-12-28}::
    <br>=== McsHitp-creation:
    <br>· creation of current <a class="clsPreview" href="../dirCor/McsCor000002.last.html#idOverview">concept</a>.
    <a class="clsHide" href="#idTchInfevg20191228"></a></p>
</section>

<section id="idTchInfwpt">
  <h1 id="idTchInfwptH1">WHOLE-PART-TREE of techInfo
    <a class="clsHide" href="#idTchInfwhlFH1"></a></h1>
  <p id="idTchInfwptnam">name::
    <br>* McsEngl.techInfo'whole-part-tree,
    <a class="clsHide" href="#idTchInfwptnam"></a></p>
  <p id="idTchInfwptchn">whole-chain::
    <br>* <a class="clsPreview" href="../dirTch/McsTch000002.last.html#idTchHmn">human-technology</a>
    <br>* Solar-system,
    <br>* Milky-way-galaxy,
    <br>* <a class="clsPreview" href="../dirCor/McsCor000003.last.html#idEntwtr">Sympan</a>,
    <a class="clsHide" href="#idTchInfwptchn"></a></p>
  <p id="idTchInfwptprt">part::
    <br>*
    <a class="clsHide" href="#idTchInfwptprt"></a></p>
</section>

<section id="idTchInfgst">
  <h1 id="idTchInfgstH1">GENERIC-SPECIFIC-TREE of techInfo
    <a class="clsHide" href="#idTchInfgstH1"></a></h1>
  <p id="idTchInfgstnam">name::
    <br>* McsEngl.techInfo'generic-specific-tree,
    <a class="clsHide" href="#idTchInfgstnam"></a></p>
  <p id="idTchInfgstgtr">generic-tree::
    <br>* <a class="clsPreview" href="../dirTch/McsTch000002.last.html#idOverview">technology</a>
    <br>...
    <br>* <a class="clsPreview" href="../dirCor/McsCor000003.last.html#idOverview">entity</a>,
    <a class="clsHide" href="#idTchInfgstchn"></a></p>

  <section id="idTchInfSpcF">
  <h2 id="idTchInfSpcFH2">techInfo.SPECIFIC
    <a class="clsHide" href="#idTchInfSpcFH2"></a></h2>
  <p id="idTchInfSpcnam">name::
    <br>* McsEngl.techInfo.specific,
    <a class="clsHide" href="#idTchInfSpcnam"></a></p>
  <p id="idTchInfSpcP1">specific::
    <br>* hardware-techInfo,
    <br>* software-techInfo,
    <br>* hardsoft-techInfo,
    <br>===
    <br>* char-techInfo,
    <br>* audio-techInfo,
    <br>* image-techInfo,
    <br>* video-techInfo,
    <br>===
    <br>* processing-techInfo,
    <br>* communicating-techInfo,
    <br>* storing-techInfo,
    <br>===
    <br>* <a class="clsPreview" href="#idTchInf001">data-techInfo</a>,
    <br>* <a class="clsPreview" href="#idTchCnpt">dataNo-techInfo</a>,
    <br>** artificial-intelligence-techInfo,
    <br>** machine-learning-techInfo,
    <br>** machine-translating-techInfo,
    <br>** natural-language-processing-techInfo,
    <br>===
    <br>* computer vision,
    <br>* speech recognition,
    <br>* natural language processing,
    <br>* machine learning,
    <br>* machine translation,
    <br>* bioinformatics,
    <br>* drug design,
    <br>* medical image analysis,
    <br>* climate science,
    <br>* material inspection,
    <br>* board game programs,
    <a class="clsHide" href="#idTchInfSpcP1"></a></p>
  </section>
</section>

<section id="idTchInf001">
  <h1 id="idTchInf001H1">techInfo.data-001
    <a class="clsHide" href="#idTchInf001H1"></a></h1>
  <p id="idTchInf001dsn">description::
    <br>· techData is techInfo that manages <a class="clsPreview" href="../dirLag/McsLag000003.last.html#idInfHmnBrn010">infoData</a>.
    <a class="clsHide" href="#idTchInf001dsn"></a></p>
  <p id="idTchInf001nam">name::
    <br>* McsEngl.techData,
    <br>* McsEngl.techInfo.001-data!⇒techData,
    <br>* McsEngl.techInfo.data!⇒techData,
    <a class="clsHide" href="#idTchInf001nam"></a></p>
</section>

<section id="idTchCnpt">
  <h1 id="idTchCnptH1">techInfo.knowledge-002 (<a class="clsPreview" href="McsTchInf000007.last.html#idLagCnptmgr">link</a>)
    <a class="clsHide" href="#idTchCnptH1"></a></h1>

  <section id="idTchCnptlgct">
  <h2 id="idTchCnptlgctH2">lagConcept (<a class="clsPreview" href="McsTchInf000007.last.html#idOverview">link</a>) of Cnptltech
    <a class="clsHide" href="#idTchCnptlgctH2"></a></h2>
  </section>
</section>

<section id="idTchInf012">
  <h1 id="idTchInf012H1">techInfo.character-012
    <a class="clsHide" href="#idTchInf012H1"></a></h1>
  <p id="idTchInf012dsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf012dsn"></a></p>
  <p id="idTchInf012nam">name::
    <br>* McsEngl.techInfo.012-character,
    <br>* McsEngl.techInfo.character,
    <a class="clsHide" href="#idTchInf012nam"></a></p>
</section>

<section id="idTchInf013">
  <h1 id="idTchInf013H1">techInfo.audio-013
    <a class="clsHide" href="#idTchInf013H1"></a></h1>
  <p id="idTchInf013dsn">description::
    <br>· speech, music, ...
    <br>"Machine hearing, also known as machine listening or computer audition, is the ability of a computer or machine to take in and process sound data such as speech or music.[8][9] This area has a wide range of application including music recording and compression, speech synthesis, and speech recognition.[10] Moreover, this technology allows the machine to replicate the human brain's ability to selectively focus on a specific sound against many other competing sounds and background noise. This particular ability is called “auditory scene analysis”. The technology enables the machine to segment several streams occurring at the same time.[8][11][12] Many commonly used devices such as a smartphones, voice translators, and cars make use of some form of machine hearing. Present technology still occasionally struggles with speech segmentation though. This means hearing words within sentences, especially when human accents are accounted for."
    <br>[{2023-04-08 retrieved} https://en.wikipedia.org/wiki/Machine_perception#Machine_hearing]
    <a class="clsHide" href="#idTchInf013dsn"></a></p>
  <p id="idTchInf013nam">name::
    <br>* McsEngl.computer-audition!⇒techAudio,
    <br>* McsEngl.machine-hearing!⇒techAudio,
    <br>* McsEngl.machine-listening!⇒techAudio,
    <br>* McsEngl.techAudio,
    <br>* McsEngl.techInfo.013-audio!⇒techAudio,
    <br>* McsEngl.techInfo.audio!⇒techAudio,
    <a class="clsHide" href="#idTchInf013nam"></a></p>
</section>

<section id="idTchInf014">
  <h1 id="idTchInf014H1">techInfo.image-014
    <a class="clsHide" href="#idTchInf014H1"></a></h1>
  <p id="idTchInf014dsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf014dsn"></a></p>
  <p id="idTchInf014nam">name::
    <br>* McsEngl.techInfo.014-image,
    <br>* McsEngl.techInfo.image,
    <a class="clsHide" href="#idTchInf014nam"></a></p>
</section>

<section id="idTchInf015">
  <h1 id="idTchInf015H1">techInfo.video-015
    <a class="clsHide" href="#idTchInf015H1"></a></h1>
  <p id="idTchInf015dsn">description::
    <br>· image and audio.
    <br>"Computer vision is a field that includes methods for acquiring, processing, analyzing, and understanding images and high-dimensional data from the real world to produce numerical or symbolic information, e.g., in the forms of decisions. Computer vision has many applications already in use today such as facial recognition, geographical modeling, and even aesthetic judgment.[7]
    <br>However, machines still struggle to interpret visual impute accurately if said impute is blurry, and if the viewpoint at which stimulus are viewed varies often. Computers also struggle to determine the proper nature of some stimulus if overlapped by or seamlessly touching another stimulus. This refers to The Principle of Good Continuation. Machines also struggle to perceive and record stimulus functioning according to the Apparent Movement principle which Gestalt psychologists researched."
    <br>[{2023-04-08 retrieved} https://en.wikipedia.org/wiki/Machine_perception#Machine_vision]
    <a class="clsHide" href="#idTchInf015dsn"></a></p>
  <p id="idTchInf015nam">name::
    <br>* McsEngl.computer-vision!⇒techVideo,
    <br>* McsEngl.machine-vision!⇒techVideo,
    <br>* McsEngl.techInfo.015-video!⇒techVideo,
    <br>* McsEngl.techInfo.video!⇒techVideo,
    <br>* McsEngl.techVideo,
    <a class="clsHide" href="#idTchInf015nam"></a></p>
</section>

<section id="idTchInf017">
  <h1 id="idTchInf017H1">techInfo.touching-017
    <a class="clsHide" href="#idTchInf017H1"></a></h1>
  <p id="idTchInf017dsn">description::
    <br>"Machine touch is an area of machine perception where tactile information is processed by a machine or computer. Applications include tactile perception of surface properties and dexterity whereby tactile information can enable intelligent reflexes and interaction with the environment.[13] (This could possibly be done through measuring when and where friction occurs, and of what nature and intensity the friction is). Machines however still do not have any way of measuring some physical human experiences we consider ordinary, including physical pain. For example, scientists have yet to invent a mechanical substitute for the Nociceptors in the body and brain that are responsible for noticing and measuring physical human discomfort and suffering."
    <br>[{2023-04-08 retrieved} https://en.wikipedia.org/wiki/Machine_perception#Machine_touch]
    <a class="clsHide" href="#idTchInf017dsn"></a></p>
  <p id="idTchInf017nam">name::
    <br>* McsEngl.techInfo.017-touching,
    <br>* McsEngl.techInfo.touching,
    <br>* McsEngl.machine-touching,
    <a class="clsHide" href="#idTchInf017nam"></a></p>
</section>

<section id="idTchInf018">
  <h1 id="idTchInf018H1">techInfo.smelling-018
    <a class="clsHide" href="#idTchInf018H1"></a></h1>
  <p id="idTchInf018dsn">description::
    <br>"Scientists are developing computers known as machine olfaction which can recognize and measure smells as well. Airborne chemicals are sensed and classified with a device sometimes known as an electronic nose.[14][15]"
    <br>[{2023-04-08 retrieved} https://en.wikipedia.org/wiki/Machine_perception#Machine_olfaction]
    <a class="clsHide" href="#idTchInf018dsn"></a></p>
  <p id="idTchInf018nam">name::
    <br>* McsEngl.electronic-nose,
    <br>* McsEngl.machine-smelling,
    <br>* McsEngl.machine-olfaction,
    <br>* McsEngl.techInfo.018-smelling,
    <br>* McsEngl.techInfo.smelling,
    <a class="clsHide" href="#idTchInf018nam"></a></p>
</section>

<section id="idTchInf019">
  <h1 id="idTchInf019H1">techInfo.tasting-019
    <a class="clsHide" href="#idTchInf019H1"></a></h1>
  <p id="idTchInf019dsn">description::
    <br>"The electronic tongue is an instrument that measures and compares tastes. As per the IUPAC technical report, an “electronic tongue” as analytical instrument including an array of non-selective chemical sensors with partial specificity to different solution components and an appropriate pattern recognition instrument, capable to recognize quantitative and qualitative compositions of simple and complex solutions[16][17]
    <br>Chemical compounds responsible for taste are detected by human taste receptors. Similarly, the multi-electrode sensors of electronic instruments detect the same dissolved organic and inorganic compounds. Like human receptors, each sensor has a spectrum of reactions different from the other. The information given by each sensor is complementary, and the combination of all sensors' results generates a unique fingerprint. Most of the detection thresholds of sensors are similar to or better than human receptors.
    <br>In the biological mechanism, taste signals are transduced by nerves in the brain into electric signals. E-tongue sensors process is similar: they generate electric signals as voltammetric and potentiometric variations.
    <br>Taste quality perception and recognition are based on the building or recognition of activated sensory nerve patterns by the brain and the taste fingerprint of the product. This step is achieved by the e-tongue's statistical software, which interprets the sensor data into taste patterns."
    <br>[{2023-04-08 retrieved} https://en.wikipedia.org/wiki/Machine_perception#Machine_taste]
    <a class="clsHide" href="#idTchInf019dsn"></a></p>
  <p id="idTchInf019nam">name::
    <br>* McsEngl.electronic-tongue,
    <br>* McsEngl.machine-tasting,
    <br>* McsEngl.techInfo.019-tasting,
    <br>* McsEngl.techInfo.tasting,
    <a class="clsHide" href="#idTchInf019nam"></a></p>
</section>

<section id="idTchInf020">
  <h1 id="idTchInf020H1">techInfo.perception-020
    <a class="clsHide" href="#idTchInf020H1"></a></h1>
  <p id="idTchInf020dsn">description::
    <br>"Machine perception is the capability of a computer system to interpret data in a manner that is similar to the way humans use their senses to relate to the world around them.[1][2][3] The basic method that the computers take in and respond to their environment is through the attached hardware. Until recently input was limited to a keyboard, or a mouse, but advances in technology, both in hardware and software, have allowed computers to take in sensory input in a way similar to humans.[1][2]
    <br>Machine perception allows the computer to use this sensory input, as well as conventional computational means of gathering information, to gather information with greater accuracy and to present it in a way that is more comfortable for the user.[1] These include computer vision, machine hearing, machine touch, and machine smelling, as artificial scents are, at a chemical compound, molecular, atomic level, indiscernible and identical.[4][5]
    <br>The end goal of machine perception is to give machines the ability to see, feel and perceive the world as humans do and therefore for them to be able to explain in a human way why they are making their decisions, to warn us when it is failing and more importantly, the reason why it is failing.[6] This purpose is very similar to the proposed purposes for artificial intelligence generally, except that machine perception would only grant machines limited sentience, rather than bestow upon machines full consciousness, self-awareness, and intentionality."
    <br>[{2023-04-08 retrieved} https://en.wikipedia.org/wiki/Machine_perception]
    <a class="clsHide" href="#idTchInf020dsn"></a></p>
  <p id="idTchInf020nam">name::
    <br>* McsEngl.machine-perception,
    <br>* McsEngl.techInfo.020-perception,
    <br>* McsEngl.techInfo.perception,
    <a class="clsHide" href="#idTchInf020nam"></a></p>
</section>

<section id="idTchInf003">
  <h1 id="idTchInf003H1">techInfo.software-003
    <a class="clsHide" href="#idTchInf003H1"></a></h1>
  <p id="idTchInf003dsn">description::
    <br>· software is techInfo which is not hardware, ie representations of infoBrain  that is-managed by the-techInfo.
    <a class="clsHide" href="#idTchInf003dsn"></a></p>
  <p id="idTchInf003nam">name::
    <br>* McsEngl.software-of-techInfo!⇒techInfoSoft,
    <br>* McsEngl.techInfo.003-software!⇒techInfoSoft,
    <br>* McsEngl.techInfo.software!⇒techInfoSoft,
    <br>* McsEngl.techInfoSoft,
    <a class="clsHide" href="#idTchInf003nam"></a></p>
</section>

<section id="idTchInf004">
  <h1 id="idTchInf004H1">techInfo.hardware-004
    <a class="clsHide" href="#idTchInf004H1"></a></h1>
  <p id="idTchInf004dsn">description::
    <br>· the physical parts of techInfo, devices, cables, anything touchable.
    <a class="clsHide" href="#idTchInf004dsn"></a></p>
  <p id="idTchInf004nam">name::
    <br>* McsEngl.hardware-techInfo!⇒techInfoHard,
    <br>* McsEngl.techInfo.004-hardware!⇒techInfoHard,
    <br>* McsEngl.techInfo.hardware!⇒techInfoHard,
    <br>* McsEngl.techInfoHard,
    <a class="clsHide" href="#idTchInf004nam"></a></p>
</section>

<section id="idTchInf005">
  <h1 id="idTchInf005H1">techInfo.system-005
    <a class="clsHide" href="#idTchInf005H1"></a></h1>
  <p id="idTchInf005dsn">description::
    <br>· machines or system of machines with hardware and software with specific doings.
    <a class="clsHide" href="#idTchInf005dsn"></a></p>
  <p id="idTchInf005nam">name::
    <br>* McsEngl.ITS!⇒techInfoSys,
    <br>* McsEngl.information-technology-system!⇒techInfoSys,
    <br>* McsEngl.techInfo.005-system!⇒techInfoSys,
    <br>* McsEngl.techInfo.machine!⇒techInfoSys,
    <br>* McsEngl.techInfo.system!⇒techInfoSys,
    <br>* McsEngl.techInfoSys,
    <a class="clsHide" href="#idTchInf005nam"></a></p>
  <p id="idTchInf005str">specific-tree-of-techInfoSys::
    <br>* <a class="clsPreview" href="McsTchInf000003.last.html#idOverview">computer</a>,
    <br>* computer-network,
    <a class="clsHide" href="#idTchInf005str"></a></p>
</section>

<section id="idTchInf007">
  <h1 id="idTchInf007H1">techInfo.artificial-intelligence-007
    <a class="clsHide" href="#idTchInf007H1"></a></h1>
  <p id="idTchInf007dsn">description::
    <br>· techAi is techInfo with <a class="clsPreview" href="../dirCor/McsCor000011.last.html#idSysMng001dngF">intelligence</a> (= doing of organism's managing-sys).
    <a class="clsHide" href="#idTchInf007dsn"></a></p>
  <p id="idTchInf007nam">name::
    <br>* McsEngl.AI'(artificial-intelligence)!⇒techAi,
    <br>* McsEngl.artificial-intelligence!⇒techAi,
    <br>* McsEngl.human-level-AI!⇒techAi,
    <br>* McsEngl.strong-AI!⇒techAi,
    <br>* McsEngl.techAi,
    <br>* McsEngl.techInfo.007-artificial-intelligence!⇒techAi,
    <br>* McsEngl.techInfo.artificial-intelligence!⇒techAi,
    <a class="clsHide" href="#idTchInf007nam"></a></p>

  <section id="idTchInf007eval">
  <h2 id="idTchInf007evalH2">evaluation of techAi
    <a class="clsHide" href="#idTchInf007evalH2"></a></h2>
  <p id="idTchInf007evalnam">name::
    <br>* McsEngl.techAi'evaluation,
    <a class="clsHide" href="#idTchInf007evalnam"></a></p>

  <section id="idTchInf007sfty">
  <h3 id="idTchInf007sftyH3">safty of techAi
    <a class="clsHide" href="#idTchInf007sftyH3"></a></h3>
  <p id="idTchInf007sftydsn">description::
    <br>"AI safety is an interdisciplinary field concerned with preventing accidents, misuse, or other harmful consequences that could result from artificial intelligence (AI) systems. It encompasses machine ethics and AI alignment, which aim to make AI systems moral and beneficial, and AI safety encompasses technical problems including monitoring systems for risks and making them highly reliable. Beyond AI research, it involves developing norms and policies that promote safety."
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/AI_safety]
    <a class="clsHide" href="#idTchInf007sftydsn"></a></p>
  <p id="idTchInf007sftynam">name::
    <br>* McsEngl.techAi'risk,
    <br>* McsEngl.techAi'safty,
    <a class="clsHide" href="#idTchInf007sftynam"></a></p>
  </section>

  <section id="idTchInf007etcs">
  <h3 id="idTchInf007etcsH3">ethics of techAi
    <a class="clsHide" href="#idTchInf007etcsH3"></a></h3>
  <p id="idTchInf007etcsdsn">description::
    <br>· Transparency, accountability, and open source.
    <br>"The ethics of artificial intelligence is the branch of the ethics of technology specific to artificially intelligent systems.[1] It is sometimes divided into a concern with the moral behavior of humans as they design, make, use and treat artificially intelligent systems, and a concern with the behavior of machines, in machine ethics. It also includes the issue of a possible singularity due to superintelligent AI."
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Ethics_of_artificial_intelligence]
    <br>
    <br>"The first global agreement on the ethics of AI was adopted in September 2021 by UNESCO's 193 Member States.[227]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Artificial_intelligence#Regulation]
    <a class="clsHide" href="#idTchInf007etcsdsn"></a></p>
  <p id="idTchInf007etcsnam">name::
    <br>* McsEngl.techAi'ethics,
    <a class="clsHide" href="#idTchInf007etcsnam"></a></p>
  </section>

  <section id="idTchInf007bias">
  <h3 id="idTchInf007biasH3">bias of techAi
    <a class="clsHide" href="#idTchInf007biasH3"></a></h3>
  <p id="idTchInf007biasdsn">description::
    <br>"AI programs can become biased after learning from real-world data. It is not typically introduced by the system designers but is learned by the program, and thus the programmers are often unaware that the bias exists.[204] Bias can be inadvertently introduced by the way training data is selected.[205] It can also emerge from correlations: AI is used to classify individuals into groups and then make predictions assuming that the individual will resemble other members of the group. In some cases, this assumption may be unfair.[206] An example of this is COMPAS, a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. ProPublica claims that the COMPAS-assigned recidivism risk level of black defendants is far more likely to be overestimated than that of white defendants, despite the fact that the program was not told the races of the defendants.[207]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Artificial_intelligence#Algorithmic_bias]
    <a class="clsHide" href="#idTchInf007biasdsn"></a></p>
  <p id="idTchInf007biasnam">name::
    <br>* McsEngl.techAi'bias,
    <a class="clsHide" href="#idTchInf007biasnam"></a></p>
  </section>

  <section id="idTchInf007wpnz">
  <h3 id="idTchInf007wpnzH3">weaponization of techAi
    <a class="clsHide" href="#idTchInf007wpnzH3"></a></h3>
  <p id="idTchInf007wpnzdsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf007wpnzdsn"></a></p>
  <p id="idTchInf007wpnznam">name::
    <br>* McsEngl.techAi'weaponization,
    <a class="clsHide" href="#idTchInf007wpnznam"></a></p>
  </section>

  <section id="idTchInf007focs">
  <h3 id="idTchInf007focsH3">failure-of-critical-systems of techAi
    <a class="clsHide" href="#idTchInf007focsH3"></a></h3>
  <p id="idTchInf007focsdsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf007focsdsn"></a></p>
  <p id="idTchInf007focsnam">name::
    <br>* McsEngl.techAi'failure-of-critical-systems,
    <a class="clsHide" href="#idTchInf007focsnam"></a></p>
  </section>

  <section id="idTchInf007svlc">
  <h3 id="idTchInf007svlcH3">surveillance of techAi
    <a class="clsHide" href="#idTchInf007svlcH3"></a></h3>
  <p id="idTchInf007svlcdsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf007svlcdsn"></a></p>
  <p id="idTchInf007svlcnam">name::
    <br>* McsEngl.techAi'surveillance,
    <a class="clsHide" href="#idTchInf007svlcnam"></a></p>
  </section>

  <section id="idTchInf007uelmt">
  <h3 id="idTchInf007uelmtH3">technological-unemployment of techAi
    <a class="clsHide" href="#idTchInf007uelmtH3"></a></h3>
  <p id="idTchInf007uelmtdsn">description::
    <br>"In the past, technology has tended to increase rather than reduce total employment, but economists acknowledge that "we're in uncharted territory" with AI.[195] A survey of economists showed disagreement about whether the increasing use of robots and AI will cause a substantial increase in long-term unemployment, but they generally agree that it could be a net benefit if productivity gains are redistributed.[196] Subjective estimates of the risk vary widely; for example, Michael Osborne and Carl Benedikt Frey estimate 47% of U.S. jobs are at "high risk" of potential automation, while an OECD report classifies only 9% of U.S. jobs as "high risk".[t][198]
    <br>Unlike previous waves of automation, many middle-class jobs may be eliminated by artificial intelligence; The Economist states that "the worry that AI could do to white-collar jobs what steam power did to blue-collar ones during the Industrial Revolution" is "worth taking seriously".[199] Jobs at extreme risk range from paralegals to fast food cooks, while job demand is likely to increase for care-related professions ranging from personal healthcare to the clergy.[200]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Artificial_intelligence#Technological_unemployment]
    <a class="clsHide" href="#idTchInf007uelmtdsn"></a></p>
  <p id="idTchInf007uelmtnam">name::
    <br>* McsEngl.techAi'technological-unemployment,
    <a class="clsHide" href="#idTchInf007uelmtnam"></a></p>
  </section>

  <section id="idTchInf007exlr">
  <h3 id="idTchInf007exlrH3">existential-risk of techAi
    <a class="clsHide" href="#idTchInf007exlrH3"></a></h3>
  <p id="idTchInf007exlrdsn">description::
    <br>"Existential risk from artificial general intelligence is the hypothesis that substantial progress in artificial general intelligence (AGI) could result in human extinction or some other unrecoverable global catastrophe.[1][2][3]
    <br>The existential risk ("x-risk") school argues as follows: The human species currently dominates other species because the human brain has some distinctive capabilities that other animals lack. If AI surpasses humanity in general intelligence and becomes "superintelligent", then it could become difficult or impossible for humans to control. Just as the fate of the mountain gorilla depends on human goodwill, so might the fate of humanity depend on the actions of a future machine superintelligence.[4]
    <br>The probability of this type of scenario is widely debated, and hinges in part on differing scenarios for future progress in computer science.[5] Concerns about superintelligence have been voiced by leading computer scientists and tech CEOs such as Geoffrey Hinton,[6] Alan Turing,[a] Elon Musk,[9] and OpenAI CEO Sam Altman.[10] As of 2022, circa half of AI researchers believe that there is a 10 percent or greater chance that our inability to control AI will cause an existential catastrophe.[11][12]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Existential_risk_from_artificial_general_intelligence]
    <a class="clsHide" href="#idTchInf007exlrdsn"></a></p>
  <p id="idTchInf007exlrnam">name::
    <br>* McsEngl.techAi'existential-risk,
    <a class="clsHide" href="#idTchInf007exlrnam"></a></p>
  </section>

  <section id="idTchInf007cprt">
  <h3 id="idTchInf007cprtH3">copyright of techAi
    <a class="clsHide" href="#idTchInf007cprtH3"></a></h3>
  <p id="idTchInf007cprtdsn">description::
    <br>"AI's decision-making abilities raises the question of legal responsibility and copyright status of created works. These issues are being refined in various jurisdictions.[219]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Artificial_intelligence#Copyright]
    <a class="clsHide" href="#idTchInf007cprtdsn"></a></p>
  <p id="idTchInf007cprtnam">name::
    <br>* McsEngl.techAi'copyright,
    <a class="clsHide" href="#idTchInf007cprtnam"></a></p>
  </section>

  <section id="idTchInf007alnt">
  <h3 id="idTchInf007alntH3">alignment of techAi
    <a class="clsHide" href="#idTchInf007alntH3"></a></h3>
  <p id="idTchInf007alntdsn">description::
    <br>"In the field of artificial intelligence (AI), AI alignment research aims to steer AI systems towards their designers’ intended goals and interests. An aligned AI system advances the intended objective; a misaligned AI system is competent at advancing some objective, but not the intended one.[1]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/AI_alignment]
    <a class="clsHide" href="#idTchInf007alntdsn"></a></p>
  <p id="idTchInf007alntnam">name::
    <br>* McsEngl.AI-alignment,
    <br>* McsEngl.AI-control-problem,
    <br>* McsEngl.techAi'alignment,
    <a class="clsHide" href="#idTchInf007alntnam"></a></p>
  </section>
  </section>

  <section id="idTchInf007appl">
  <h2 id="idTchInf007applH2">application of techAi
    <a class="clsHide" href="#idTchInf007applH2"></a></h2>
  <p id="idTchInf007appldsn">description::
    <br>* <a class="clsPreview" href="#idTchInf010">computer-vision</a>,
    <br>* machine-learning,
    <br>* machine-reasoning,
    <br>* natural-language-understanding,
    <br>===
    <br>* in education,
    <br>* in government,
    <br>* in economy,
    <a class="clsHide" href="#idTchInf007appldsn"></a></p>
  <p id="idTchInf007applnam">name::
    <br>* McsEngl.techAi'application,
    <br>* McsEngl.techAi'use,
    <a class="clsHide" href="#idTchInf007applnam"></a></p>
  </section>

  <section id="idTchInf007lbrr">
  <h2 id="idTchInf007lbrrH2">library of techAi
    <a class="clsHide" href="#idTchInf007lbrrH2"></a></h2>
  <p id="idTchInf007lbrrdsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf007lbrrdsn"></a></p>
  <p id="idTchInf007lbrrnam">name::
    <br>* McsEngl.techAi'library,
    <a class="clsHide" href="#idTchInf007lbrrnam"></a></p>
  </section>

  <section id="idTchInf007rgln">
  <h2 id="idTchInf007rglnH2">regulation of techAi
    <a class="clsHide" href="#idTchInf007rglnH2"></a></h2>
  <p id="idTchInf007rglndsn">description::
    <br>"The regulation of artificial intelligence is the development of public sector policies and laws for promoting and regulating artificial intelligence (AI); it is therefore related to the broader regulation of algorithms. The regulatory and policy landscape for AI is an emerging issue in jurisdictions globally, including in the European Union and in supra-national bodies like the IEEE, OECD and others. Since 2016, a wave of AI ethics guidelines have been published in order to maintain social control over the technology.[1] Regulation is considered necessary to both encourage AI and manage associated risks. In addition to regulation, AI-deploying organizations need to play a central role in creating and deploying trustworthy AI in line with the principles of trustworthy AI,[2] and take accountability to mitigate the risks.[3] Regulation of AI through mechanisms such as review boards can also be seen as social means to approach the AI control problem.[4][5]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Regulation_of_artificial_intelligence]
    <a class="clsHide" href="#idTchInf007rglndsn"></a></p>
  <p id="idTchInf007rglnnam">name::
    <br>* McsEngl.AI-regulation,
    <br>* McsEngl.techAi'regulation,
    <a class="clsHide" href="#idTchInf007rglnnam"></a></p>
  </section>

  <section id="idTchInf007ozn">
  <h2 id="idTchInf007oznH2">organization of techAi
    <a class="clsHide" href="#idTchInf007oznH2"></a></h2>
  <p id="idTchInf007ozndsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf007ozndsn"></a></p>
  <p id="idTchInf007oznnam">name::
    <br>* McsEngl.oznAi,
    <br>* McsEngl.techAi'organization!⇒oznAi,
    <a class="clsHide" href="#idTchInf007oznnam"></a></p>

  <section id="idTchInf007oznGpai">
  <h3 id="idTchInf007oznGpaiH3">oznAi.GPAI
    <a class="clsHide" href="#idTchInf007oznGpaiH3"></a></h3>
  <p id="idTchInf007oznGpaidsn">description::
    <br>"The Global Partnership on Artificial Intelligence (GPAI, or "gee-pay") is an international and multi-stakeholder initiative that aims to advance the responsible and human-centric development and use of artificial intelligence.[2] Specifically, GPAI brings together leading experts from science, industry, civil society, and governments to "bridge the gap between theory and practice" through applied AI projects and activities.[3] The goal is to facilitate international collaboration, reduce duplication between governments, and act as a global reference point on discussions on responsible AI.[3][4]
    <br>First announced on the margins of the 2018 G7 Summit by Canadian Prime Minister Justin Trudeau and French President Emmanuel Macron, GPAI officially launched on June 15, 2020[5] with fifteen founding members: Australia, Canada, France, Germany, India,[6] Italy, Japan, Mexico, New Zealand, the Republic of Korea, Singapore, Slovenia, the United Kingdom, the United States and the European Union.[7][8] The OECD hosts a dedicated secretariat to support GPAI's governing bodies and activities.[7] UNESCO joined the partnership in December 2020 as an observer.[9][7] On November 11, 2021, Czechia, Israel and few more EU countries also joined the GPAI,[10] bringing the total membership to 25 countries.[2] Since the November 2022 summit, the list of members stands at 29, with in addition to the above, Belgium, Brazil, Denmark, Ireland, The Netherlands, Poland, Senegal, Serbia, Sweden, and Turkey.[11]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Global_Partnership_on_Artificial_Intelligence]
    <a class="clsHide" href="#idTchInf007oznGpaidsn"></a></p>
  <p id="idTchInf007oznGpainam">name::
    <br>* McsEngl.GPAI!⇒oznGpai,
    <br>* McsEngl.GPAI-Global-Partnership-on-Artificial-Intelligence!⇒oznGpai,
    <br>* McsEngl.Global-Partnership-on-Artificial-Intelligence!⇒oznGpai,
    <br>* McsEngl.oznAi.GPAI!⇒oznGpai,
    <br>* McsEngl.oznGpai,
    <a class="clsHide" href="#idTchInf007oznGpainam"></a></p>
  </section>
  </section>

  <section id="idTchInf007rscF">
  <h2 id="idTchInf007rscFH2">info-resource of techAi
    <a class="clsHide" href="#idTchInf007rscFH2"></a></h2>
  <p id="idTchInf007rscFdsn">description::
    <br>* https://www.stateof.ai/,
    <br>* https://welcome.ai/about,
    <br>* https://knowledge4policy.ec.europa.eu/ai-watch_en,
    <br>* https://joinup.ec.europa.eu/collection/elise-european-location-interoperability-solutions-e-government/artificial-intelligence-public-sector,
    <br>* {2021-01-15} https://www.weforum.org/agenda/2021/01/ai-agriculture-water-irrigation-farming,
    <br>* {2020} Blagoj DELIPETREV, Chrisa TSINARAKIi, Uroš KOSTIĆ. “Historical Evolution of Artificial Intelligence”, EUR 30221EN, Publications Office of the European Union, Luxembourg, 2020, ISBN 978-92-76-18940-4, doi:10.2760/801580, JRC120469: https://publications.jrc.ec.europa.eu/repository/handle/JRC120469,
    <br>* {1995-12-26} http://sandcastle.cosc.brocku.ca/~bross/3P71/misc/outsider_ai.txt,
    <a class="clsHide" href="#idTchInf007rscFdsn"></a></p>
  <p id="idTchInf007rscFnam">name::
    <br>* McsEngl.techAi'Infrsc,
    <a class="clsHide" href="#idTchInf007rscFnam"></a></p>
  </section>

  <section id="idTchInf007evg">
  <h2 id="idTchInf007evgH2">evoluting of techAi
    <a class="clsHide" href="#idTchInf007evgH2"></a></h2>
  <p id="idTchInf00720230314">{2023-03-14}-techAi-GPT-4::
    <br>"We’ve created GPT-4, the latest milestone in OpenAI’s effort in scaling up deep learning. GPT-4 is a large multimodal model (accepting image and text inputs, emitting text outputs) that, while less capable than humans in many real-world scenarios, exhibits human-level performance on various professional and academic benchmarks."
    <br>[https://openai.com/research/gpt-4]
    <br>* McsEngl.{techInfo'2023-03-14}-GPT-4,
    <br>* McsEngl.{2023-03-14}-techAi-GPT-4,
    <a class="clsHide" href="#idTchInf00720230314"></a></p>
  <p id="idTchInf0072017">{2017}-techAi-Transformer::
    <br>"Transformers were introduced in 2017 by a team at Google Brain[1] and are increasingly becoming the model of choice for NLP problems,[3] replacing RNN models such as long short-term memory (LSTM)."
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)]
    <br>* McsEngl.{techInfo'2017}-techAi-Transformers,
    <br>* McsEngl.{2017}-techAi-Transformers,
    <a class="clsHide" href="#idTchInf0072017"></a></p>
  <p id="idTchInf0072015">{2015}-techAi-landmark-year::
    <br>"According to Bloomberg's Jack Clark, 2015 was a landmark year for artificial intelligence, with the number of software projects that use AI within Google increased from a "sporadic usage" in 2012 to more than 2,700 projects.[i] He attributed this to an increase in affordable neural networks, due to a rise in cloud computing infrastructure and to an increase in research tools and datasets.[7]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Artificial_intelligence#]
    <br>* McsEngl.{techInfo'2015}-techAi-landmark-year,
    <br>* McsEngl.{2015}-techAi-landmark-year,
    <a class="clsHide" href="#idTchInf0072015"></a></p>
  <p id="idTchInf00719871993">{1987..1993}-techAi-2nd-winter::
    <br>· 2nd major AI winter.
    <br>[{2023-04-04 retrieved} https://en.wikipedia.org/wiki/AI_winter]
    <br>* McsEngl.{techInfo'1987..1993}-techAi-2nd-winter,
    <br>* McsEngl.{1987..1993}-techAi-2nd-winter,
    <a class="clsHide" href="#idTchInf00719871993"></a></p>
  <p id="idTchInf0071980s">{1980s}-techAi-expert-systems::
    <br>"In the early 1980s, AI research was revived by the commercial success of expert systems,[34] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[4] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[6]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Artificial_intelligence]
    <br>* McsEngl.{techInfo'1980s}-techAi-expert-systems,
    <br>* McsEngl.{1980s}-techAi-expert-systems,
    <a class="clsHide" href="#idTchInf0071980s"></a></p>
  <p id="idTchInf00719741980">{1974..1980}-techAi-1st-winter::
    <br>· 1st major AI winter.
    <br>[{2023-04-04 retrieved} https://en.wikipedia.org/wiki/AI_winter]
    <br>* McsEngl.{techInfo'1974..1980}-techAi-1st-winter,
    <br>* McsEngl.{1974..1980}-techAi-1st-winter,
    <a class="clsHide" href="#idTchInf00719741980"></a></p>
  <p id="idTchInf0071969">{1969}-techAi-Shakey-the-Robot::
    <br>"1969 Shakey the Robot was the first general-purpose mobile robot capable of reasoning its actions. This project integrated research in robotics with computer vision and natural language processing, thus being the first project that combined logical reasoning and physical action (Bertram 1972)."
    <br>[{2020} Historical-Evolution-of-AI, p7, <a class="clsPreview" href="../dirLag/McsLag000013.last.html#idInfrscElnc000001">ifrcElnc000001</a>]
    <br>* McsEngl.{1969}-techAi-Shakey-the-Robot,
    <a class="clsHide" href="#idTchInf0071969"></a></p>
  <p id="idTchInf0071956">{1956}-techAi-Dartmouth-conference::
    <br>"The first “AI period” began with the Dartmouth conference in 1956, where AI got its name and mission.
    <br>McCarthy coined the term "artificial intelligence," which became the name of the scientific field.
    <br>The primary conference assertion was, "Every aspect of any other feature of learning or intelligence should be accurately described so that the machine can simulate it” (Russell and Norvig 2016).
    <br>Among the conference attendees were Ray Solomonoff, Oliver Selfridge, Trenchard More, Arthur Samuel, Herbert A. Simon, and Allen Newell, all of whom became key figures in the Ai field"
    <br>[{2020} Historical-Evolution-of-AI, p7, <a class="clsPreview" href="../dirLag/McsLag000013.last.html#idInfrscElnc000001">ifrcElnc000001</a>]
    <br>* McsEngl.{1956}-techAi-Dartmouth-conference,
    <a class="clsHide" href="#idTchInf0071956"></a></p>
  <p id="idTchInf0071955">{1955}-techAi-Logic-Theorist::
    <br>"1955 The Logic Theorist had proven 38 theorems from Principia Mathematica and introduced critical concepts in artificial intelligence, like heuristics, list processing, ‘reasoning as search,' etc. (Newell et al. 1962)."
    <br>[{2020} Historical-Evolution-of-AI, p7, <a class="clsPreview" href="../dirLag/McsLag000013.last.html#idInfrscElnc000001">ifrcElnc000001</a>]
    <br>* McsEngl.{1955}-techAi-Logic-Theorist,
    <a class="clsHide" href="#idTchInf0071955"></a></p>
  <p id="idTchInf0071950">{1950}-techAi-Turing-test::
    <br>"In 1950, Alan Turing published the milestone paper "Computing machinery and intelligence" (Turing 1950), considering the fundamental question "Can machines think?”
    <br>Turing proposed an imitation game, known as the Turing test afterwards, where if a machine could carry on a conversation indistinguishable from a conversation with a human being, then it is reasonable to say that the machine is intelligent.
    <br>The Turing test was the first experiment proposed to measure machine intelligence"
    <br>[{2020} Historical-Evolution-of-AI, p7, <a class="clsPreview" href="../dirLag/McsLag000013.last.html#idInfrscElnc000001">ifrcElnc000001</a>]
    <br>* McsEngl.{1950}-techAi-Turing-test,
    <a class="clsHide" href="#idTchInf0071950"></a></p>
  <p id="idTchInf0071943">{1943}-techAi-first-work::
    <br>"The first work that is now generally recognized as AI was McCullouch and Pitts' 1943 formal design for Turing-complete "artificial neurons".[20]"
    <br>* McsEngl.{techInfo'1943}-techAi-first-work,
    <br>* McsEngl.{1943}-techAi-first-work,
    <a class="clsHide" href="#idTchInf0071943"></a></p>
  <p id="idTchInf007evgnam">name::
    <br>* McsEngl.techAi'evoluting,
    <a class="clsHide" href="#idTchInf007evgnam"></a></p>

  <section id="idTchInf007evgwntr">
  <h3 id="idTchInf007evgwntrH3">winter of techAi
    <a class="clsHide" href="#idTchInf007evgwntrH3"></a></h3>
  <p id="idTchInf007evgwntrdsn">description::
    <br>"In the history of artificial intelligence, an AI winter is a period of reduced funding and interest in artificial intelligence research.[1] The term was coined by analogy to the idea of a nuclear winter.[2] The field has experienced several hype cycles, followed by disappointment and criticism, followed by funding cuts, followed by renewed interest years or even decades later.
    <br>The term first appeared in 1984 as the topic of a public debate at the annual meeting of AAAI (then called the "American Association of Artificial Intelligence"). It is a chain reaction that begins with pessimism in the AI community, followed by pessimism in the press, followed by a severe cutback in funding, followed by the end of serious research.[2] At the meeting, Roger Schank and Marvin Minsky—two leading AI researchers who had survived the "winter" of the 1970s—warned the business community that enthusiasm for AI had spiraled out of control in the 1980s and that disappointment would certainly follow. Three years later, the billion-dollar AI industry began to collapse.[2]
    <br>Hype is common in many emerging technologies, such as the railway mania or the dot-com bubble. The AI winter was a result of such hype, due to over-inflated promises by developers, unnaturally high expectations from end-users, and extensive promotion in the media.[3] Despite the rise and fall of AI's reputation, it has continued to develop new and successful technologies. AI researcher Rodney Brooks would complain in 2002 that "there's this stupid myth out there that AI has failed, but AI is around you every second of the day."[4] In 2005, Ray Kurzweil agreed: "Many observers still think that the AI winter was the end of the story and that nothing since has come of the AI field. Yet today many thousands of AI applications are deeply embedded in the infrastructure of every industry."[5]
    <br>Enthusiasm and optimism about AI has generally increased since its low point in the early 1990s. Beginning about 2012, interest in artificial intelligence (and especially the sub-field of machine learning) from the research and corporate communities led to a dramatic increase in funding and investment."
    <br>[{2023-04-04 retrieved} https://en.wikipedia.org/wiki/AI_winter]
    <a class="clsHide" href="#idTchInf007evgwntrdsn"></a></p>
  <p id="idTchInf007evgwntrnam">name::
    <br>* McsEngl.AI-winter,
    <br>* McsEngl.techAi'winter,
    <a class="clsHide" href="#idTchInf007evgwntrnam"></a></p>
  </section>
  </section>

  <section id="idTchInf007gtr">
  <h2 id="idTchInf007gtrH2">GENERIC of techAi
    <a class="clsHide" href="#idTchInf007gtrH2"></a></h2>
  <p id="idTchInf007gtrdsn">description::
    <br>* <a class="clsPreview" href="../dirTch/McsTch000002.last.html#idTch003">tool</a>,
    <br>===
    <br>"Human beings across time have shared one important characteristic: they use tools to improve what they can achieve.
    <br>AI can be one such tool, and it can work well, provided we remember it is a tool. As a tool it must be put in the hands of a human, who can use appropriately and intentionally, for achieving the goals they have."
    <br>[{2020-10-08} https://clearbox.ai/blog/2020-06-16-making-ai-less-magic-and-more-human/]
    <a class="clsHide" href="#idTchInf007gtrdsn"></a></p>
  <p id="idTchInf007gtrnam">name::
    <br>* McsEngl.techAi'generic,
    <a class="clsHide" href="#idTchInf007gtrnam"></a></p>
  </section>

  <section id="idTchInf007Spc">
  <h2 id="idTchInf007SpcH2">techAi.SPECIFIC
    <a class="clsHide" href="#idTchInf007SpcH2"></a></h2>
  <p id="idTchInf007Spcdsn">description::
    <br>* <a class="clsPreview" href="#idTchInf007Smtc">semantic-AI</a>,
    <br>* <a class="clsPreview" href="#idTchInf007Stcl">statistical-AI</a>,
    <br>===
    <br>* <a class="clsPreview" href="#idTchInf007Gnrl">general-AI</a>,
    <br>* <a class="clsPreview" href="#idTchInf007Nrw">specific-AI</a>,
    <br>===
    <br>* <a class="clsPreview" href="#idTchInf008">machine-learning</a>,
    <br>* <a class="clsPreview" href="#idTchInf009">neural-network</a>,
    <a class="clsHide" href="#idTchInf007Spcdsn"></a></p>
  <p id="idTchInf007Spcnam">name::
    <br>* McsEngl.techAi.specific,
    <a class="clsHide" href="#idTchInf007Spcnam"></a></p>
  </section>

  <section id="idTchInf007rpbl">
  <h2 id="idTchInf007rpblH2">techAi.responsible
    <a class="clsHide" href="#idTchInf007rpblH2"></a></h2>
  <p id="idTchInf007rpbldsn">description::
    <br>"According to Google, responsible AI means not just avoiding risks, but also finding ways to improve people’s lives and address social and scientific problems, as these new technologies have applications in predicting disasters, improving medicine, precision agriculture, and more. "
    <br>[{2023-03-31 retrieved} https://sdtimes.com/ai/google-outlines-four-principles-for-responsible-ai/]
    <a class="clsHide" href="#idTchInf007rpbldsn"></a></p>
  <p id="idTchInf007rpblnam">name::
    <br>* McsEngl.responsible-AI,
    <br>* McsEngl.techAi.responsible,
    <a class="clsHide" href="#idTchInf007rpblnam"></a></p>

  <section id="idTchInf007rpblrsc">
  <h3 id="idTchInf007rpblrscH3">info-resource of responsible-AI
    <a class="clsHide" href="#idTchInf007rpblrscH3"></a></h3>
  <p id="idTchInf007rpblrscdsn">description::
    <br>* https://www.oecd.org/digital/artificial-intelligence/,
    <a class="clsHide" href="#idTchInf007rpblrscdsn"></a></p>
  <p id="idTchInf007rpblrscnam">name::
    <br>* McsEngl.responsible-AI'Infrsc,
    <a class="clsHide" href="#idTchInf007rpblrscnam"></a></p>
  </section>
  </section>

  <section id="idTchInf007Nrw">
  <h2 id="idTchInf007NrwH2">techAi.narrow
    <a class="clsHide" href="#idTchInf007NrwH2"></a></h2>
  <p id="idTchInf007Nrwdsn">description::
    <br>"Artificial Narrow Intelligence (ANI), often referred to as “Weak” AI is the type of AI that mostly exists today. ANI systems can perform one or a few specific tasks and operate within a predefined environment, e.g., those exploited by personal assistants Siri, Alexa, language translations, recommendation systems, image recognition systems, face identification, etc.
    <br>ANI can process data at lightning speed and boost the overall productivity and efficiency in many practical applications, e.g., translate between 100+ languages simultaneously, identify faces and objects in billions of images with high accuracy, assist users in many data-driven decisions in a quicker way. ANI can perform routine, repetitive, and mundane tasks that humans would prefer to avoid."
    <br>[{2020} Historical-Evolution-of-AI, <a class="clsPreview" href="../dirLag/McsLag000013.last.html#idInfrscElnc000001">ifrcElnc000001</a>]
    <a class="clsHide" href="#idTchInf007Nrwdsn"></a></p>
  <p id="idTchInf007Nrwnam">name::
    <br>* McsEngl.ANI'(Artificial-Narrow-Inteligence),
    <br>* McsEngl.ASI'(Artificial-Specific-Inteligence),
    <br>* McsEngl.Artificial-Narrow-Inteligence,
    <br>* McsEngl.techAi.narrow,
    <br>* McsEngl.weak-AI,
    <a class="clsHide" href="#idTchInf007Nrwnam"></a></p>
  </section>

  <section id="idTchInf007Gnrl">
  <h2 id="idTchInf007GnrlH2">techAi.general
    <a class="clsHide" href="#idTchInf007GnrlH2"></a></h2>
  <p id="idTchInf007Gnrldsn">description::
    <br>"Artificial General Intelligence (AGI) or “Strong” AI refers to machines that exhibit human intelligence. In other words, AGI aims to perform any intellectual task that a human being can. AGI is often illustrated in science fiction movies with situations where humans interact with machines that are conscious, sentient, and driven by emotion and self-awareness. At this moment, there is nothing like an AGI."
    <br>[{2020} Historical-Evolution-of-AI, <a class="clsPreview" href="../dirLag/McsLag000013.last.html#idInfrscElnc000001">ifrcElnc000001</a>]
    <a class="clsHide" href="#idTchInf007Gnrldsn"></a></p>
  <p id="idTchInf007Gnrlnam">name::
    <br>* McsEngl.AGI'(Artificial-General-Intelligence)!⇒techAgi,
    <br>* McsEngl.Artificial-General-Intelligence!⇒techAgi,
    <br>* McsEngl.techAgi,
    <br>* McsEngl.techAi.general!⇒techAgi,
    <a class="clsHide" href="#idTchInf007Gnrlnam"></a></p>

  <section id="idTchInf007Gnrlrsc">
  <h3 id="idTchInf007GnrlrscH3">info-resource of techAgi
    <a class="clsHide" href="#idTchInf007GnrlrscH3"></a></h3>
  <p id="idTchInf007Gnrlrscdsn">description::
    <br>* {2023} https://blog.finxter.com/what-is-artificial-general-intelligence-a-comprehensive-overview/
    <a class="clsHide" href="#idTchInf007Gnrlrscdsn"></a></p>
  <p id="idTchInf007Gnrlrscnam">name::
    <br>* McsEngl.techAgi'Infrsc,
    <a class="clsHide" href="#idTchInf007Gnrlrscnam"></a></p>
  </section>
  </section>

  <section id="idTchInf007Spr">
  <h2 id="idTchInf007SprH2">techAi.supper
    <a class="clsHide" href="#idTchInf007SprH2"></a></h2>
  <p id="idTchInf007Sprdsn">description::
    <br>"Artificial Superintelligence (ASI) is defined as “any intellect that greatly exceeds the cognitive performance of humans in virtually all domains of interest” (Bostrom 2016). ASI is supposed to surpass human intelligence in all aspects — such as creativity, general wisdom, and problem-solving. ASI is supposed to be capable of exhibiting intelligence that we have not seen in the brightest thinkers amongst us. Many thinkers are worried about ASI. At this moment, ASI belongs to science fiction.
    <br>If we ever succeed in creating an AI that is capable of generalizing, understanding causality, making a model of the world, it is highly likely that it will be closer to ASI than AGI. AI excels in numerical calculations, and there is no logical explanation as to why AI would downgrade its abilities to simulate humans. AI’s quest ultimately leads to ASI."
    <br>[{2020} Historical-Evolution-of-AI, <a class="clsPreview" href="../dirLag/McsLag000013.last.html#idInfrscElnc000001">ifrcElnc000001</a>]
    <a class="clsHide" href="#idTchInf007Sprdsn"></a></p>
  <p id="idTchInf007Sprnam">name::
    <br>* McsEngl.ASI'(Artificial-Superintelligence),
    <br>* McsEngl.Artificial-Superintelligence,
    <br>* McsEngl.techAi.supper,
    <a class="clsHide" href="#idTchInf007Sprnam"></a></p>
  </section>

  <section id="idTchInf007Smtc">
  <h2 id="idTchInf007SmtcH2">techAi.semantic
    <a class="clsHide" href="#idTchInf007SmtcH2"></a></h2>
  <p id="idTchInf007Smtcdsn">description::
    <br>"Semantic AI is used everywhere where the complexity of the underlying data is high and the details must not be ignored.
    <br>This distinguishes semantic AI from AI based on statistical methods (e.g. neural networks): statistical AI generalizes but details and traceability are lost. This is not bad for the classification of images - but not acceptable for the representation of processes or contracts."
    <br>[{2021-02-04} https://www.semafora-systems.com/]
    <br>"Historically, there have been two dominant paradigms of AI, namely symbolism and connectionism. Symbolism conjectures that symbols representing things in the world are the fundamental units of human intelligence, and that the cognitive process can be accomplished by the manipulation of the symbols, through a series of rules and logic operations upon the symbolic representations [2], [3]. Many early AI systems, from the middle 1950s to the late 1980s, were built upon symbolistic models. Symbolic methods have several virtues: they require only a few input samples, use powerful declarative languages for knowledge representation, and have conceptually straightforward internal functionality. It soon became apparent, however, that such a rule-based, top-down strategy demands substantial hand-tuning and lacks true learning. As discrete symbolic representations and hand-crafted rules are intolerant of ambiguous and noisy data, symbolic approaches typically fall short when solving real-world problems."
    <br>[{2023-03-29 retrieved} https://arxiv.org/pdf/2210.15889.pdf]
    <a class="clsHide" href="#idTchInf007Smtcdsn"></a></p>
  <p id="idTchInf007Smtcnam">name::
    <br>* McsEngl.semantic-AI,
    <br>* McsEngl.symbolic-AI,
    <br>* McsEngl.techAi.semantic,
    <br>* McsEngl.techAi.symbolism,
    <a class="clsHide" href="#idTchInf007Smtcnam"></a></p>
  </section>

  <section id="idTchInf007Stcl">
  <h2 id="idTchInf007StclH2">techAi.statistical
    <a class="clsHide" href="#idTchInf007StclH2"></a></h2>
  <p id="idTchInf007Stcldsn">description::
    <br>"Statistical AI and classical AI are two different approaches to artificial intelligence (AI).Statistical AI, also known as machine learning, is a method of teaching computers to learn from data. It involves using statistical techniques to analyze large amounts of data and make predictions or decisions based on that data. This approach is often used in applications such as image recognition, natural language processing, and predictive analytics.Classical AI, on the other hand, is an approach that involves creating explicit rules and algorithms for a computer to follow. This approach is often used in applications such as expert systems and decision-making systems. It is based on symbolic reasoning and rule-based systems.While both approaches have their own advantages and limitations, they can also be combined to create more sophisticated AI systems."
    <br>[{2023-03-29 retrieved} https://www.quora.com/What-is-statistical-AI-and-classical-AI]
    <br>===
    <br>"From the earliest days, AI research has tended to fall into two largely separate strands: one focused on logical representations, and one focused on statistical ones. The first strand includes approacheslike logic programming, description logics, classical planning, symbolic parsing, rule induction, etc. The second includes approaches like Bayesian networks, hidden Markov models, Markov decision processes, statistical parsing, neural networks, etc. Logical approaches tend to emphasize handling complexity, and statistical ones uncertainty. Clearly, however, both of these are necessary to build intelligent agents and handle real-world applications"
    <br>[{2023-03-29 retrieved} https://homes.cs.washington.edu/~pedrod/papers/aaai06c.pdf]
    <br>===
    <br>"Connectionism, known by its most successful technique, deep neural networks (DNNs) [4], serves as the architecture behind the vast majority of recent successful AI systems. Inspired by the physiology of the nervous system, connectionism explains cognition by interconnected networks of simple and often uniform units. Learning happens as weight modification, in a data-driven manner; the network weights are adjusted in the direction that minimises the cumulative error from all the training samples, using techniques such as gradient back-propagation [5]. Connectionist models are fault-tolerant, as they learn sub-symbolics, i.e., continuous embedding vectors, and compare these vectorized representations instead of the literal meaning between entities and relations by discrete symbolic representations. Moreover, by learning statistical patterns from data, connectionist models enjoy the advantages of inductive learning and generalization capabilities. Like every coin has two sides, such approaches also suffer from several fundamental problems [6], [7]. First, connectionist models fall significantly short of compositional generalization, the robust ability of human cognition to correctly solve any problem that is composed of familiar parts [8]. Second, such bottom-up approaches are known to be data inefficient. Third, connectionist models are logically opaque, lacking comprehensibility. It is almost impossible to understand why decisions are made. In the absence of any kind of identifiable or verifiable train of logic, people are left with systems that are making potentially catastrophic decisions that are difficult to understand, arduous to correct, and therefore hard to be trusted. These shortcomings hinder the adoption of connectionist systems in decision-critical applications and reasoning-heavy tasks, such as medical diagnosis, autonomous driving, and mathematical reasoning, and lead to the increasing concern about contemporary AI techniques."
    <br>[{2023-03-29 retrieved} https://arxiv.org/pdf/2210.15889.pdf]
    <a class="clsHide" href="#idTchInf007Stcldsn"></a></p>
  <p id="idTchInf007Stclnam">name::
    <br>* McsEngl.connectionist-AI,
    <br>* McsEngl.statistical-AI,
    <br>* McsEngl.techAi.connectionism,
    <br>* McsEngl.techAi.statistical,
    <a class="clsHide" href="#idTchInf007Stclnam"></a></p>
  </section>

  <section id="idTchInf007Sas">
  <h2 id="idTchInf007SasH2">techAi.semantic-and-statistical
    <a class="clsHide" href="#idTchInf007SasH2"></a></h2>
  <p id="idTchInf007Sasdsn">description::
    <br>"By the 1950s, two visions for how to achieve machine intelligence emerged. One vision, known as Symbolic AI or GOFAI, was to use computers to create a symbolic representation of the world and systems that could reason about the world. Proponents included Allen Newell, Herbert A. Simon, and Marvin Minsky. Closely associated with this approach was the "heuristic search" approach, which likened intelligence to a problem of exploring a space of possibilities for answers.
    <br>The second vision, known as the connectionist approach, sought to achieve intelligence through learning. Proponents of this approach, most prominently Frank Rosenblatt, sought to connect Perceptron in ways inspired by connections of neurons.[21] <span class="clsColorRed">James Manyika and others have compared the two approaches to the mind (Symbolic AI) and the brain (connectionist)</span>. Manyika argues that symbolic approaches dominated the push for artificial intelligence in this period, due in part to its connection to intellectual traditions of Descartes, Boole, Gottlob Frege, Bertrand Russell, and others. Connectionist approaches based on cybernetics or artificial neural networks were pushed to the background but have gained new prominence in recent decades.[22]"
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Artificial_intelligence#]
    <a class="clsHide" href="#idTchInf007Sasdsn"></a></p>
  <p id="idTchInf007Sasnam">name::
    <br>* McsEngl.NeSy-neural-symbolic-computing!⇒techAiSas,
    <br>* McsEngl.connectionist-and-symbolic-techAi!⇒techAiSas,
    <br>* McsEngl.neuro-symbolic-techAi!⇒techAiSas,
    <br>* McsEngl.semantic-and-statistical-techAi!⇒techAiSas,
    <br>* McsEngl.symbolic-and-connectionist-techAi!⇒techAiSas,
    <br>* McsEngl.techAiSas,
    <br>* McsEngl.techAi.semantic-and-statistical!⇒techAiSas,
    <a class="clsHide" href="#idTchInf007Sasnam"></a></p>
  </section>

  <section id="idTchInf007Cnpt">
  <h2 id="idTchInf007CnptH2">techAi.conceptual (<a class="clsPreview" href="McsTchInf000007.last.html#idLagCnptmgr">link</a>)
    <a class="clsHide" href="#idTchInf007CnptH2"></a></h2>
  </section>

  <section id="idTchInf007Frdl">
  <h2 id="idTchInf007FrdlH2">techAi.friendly
    <a class="clsHide" href="#idTchInf007FrdlH2"></a></h2>
  <p id="idTchInf007Frdldsn">description::
    <br>"Friendly artificial intelligence (also friendly AI or FAI) refers to hypothetical artificial general intelligence (AGI) that would have a positive (benign) effect on humanity or at least align with human interests or contribute to fostering the improvement of the human species. It is a part of the ethics of artificial intelligence and is closely related to machine ethics. While machine ethics is concerned with how an artificially intelligent agent should behave, friendly artificial intelligence research is focused on how to practically bring about this behavior and ensuring it is adequately constrained."
    <br>[{2023-04-10 retrieved} https://en.wikipedia.org/wiki/Friendly_artificial_intelligence]
    <a class="clsHide" href="#idTchInf007Frdldsn"></a></p>
  <p id="idTchInf007Frdlnam">name::
    <br>* McsEngl.FAI-friendly-AI,
    <br>* McsEngl.friendly-AI,
    <br>* McsEngl.techAi.friendly,
    <a class="clsHide" href="#idTchInf007Frdlnam"></a></p>
  </section>
</section>

<section id="idTchInf006">
  <h1 id="idTchInf006H1">techInfo.natural-language-processing-006
    <a class="clsHide" href="#idTchInf006H1"></a></h1>
  <p id="idTchInf006dsn">description::
    <br>"Natural Language Processing (NLP) comprises a set of techniques to work with documents written in a natural language to achieve many different objectives. They range from simple ones that any developer can implement, to extremely complex ones that require a lot of expertise."
    <br>[{2020-09-20} https://tomassetti.me/guide-natural-language-processing/]
    <a class="clsHide" href="#idTchInf006dsn"></a></p>
  <p id="idTchInf006nam">name::
    <br>* McsEngl.NLP!⇒techNlp,
    <br>* McsEngl.natural-language-processing-tech!⇒techNlp,
    <br>* McsEngl.techInfo.006-natural-language-processing!⇒techNlp,
    <br>* McsEngl.techInfo.natural-language-processing!⇒techNlp,
    <br>* McsEngl.techNlp,
    <a class="clsHide" href="#idTchInf006nam"></a></p>

  <section id="idTchInf006001lgml">
  <h2 id="idTchInf006001lgmlH2">language-model of techNlp
    <a class="clsHide" href="#idTchInf006001lgmlH2"></a></h2>
  <p id="idTchInf006001lgmldsn">description::
    <br>"A language model is a probability distribution over sequences of words.[1] Given any sequence of words of length m, a language model assigns a probability P(w1,...,wm) to the whole sequence. Language models generate probabilities by training on text corpora in one or many languages. Given that languages can be used to express an infinite variety of valid sentences (the property of digital infinity), language modeling faces the problem of assigning non-zero probabilities to linguistically valid sequences that may never be encountered in the training data. Several modelling approaches have been designed to surmount this problem, such as applying the Markov assumption or using neural architectures such as recurrent neural networks or transformers.
    <br>Language models are useful for a variety of problems in computational linguistics; from initial applications in speech recognition[2] to ensure nonsensical (i.e. low-probability) word sequences are not predicted, to wider use in machine translation[3] (e.g. scoring candidate translations), natural language generation (generating more human-like text), part-of-speech tagging, parsing,[3] optical character recognition, handwriting recognition,[4] grammar induction,[5] information retrieval,[6][7] and other applications."
    <br>[{2023-03-31 retrieved} https://en.wikipedia.org/wiki/Language_model]
    <a class="clsHide" href="#idTchInf006001lgmldsn"></a></p>
  <p id="idTchInf006001lgmlnam">name::
    <br>* McsEngl.language-model-techNlp!⇒techNlplm,
    <br>* McsEngl.techNlp'language-model!⇒techNlplm,
    <br>* McsEngl.techNlplm,
    <br>* McsEngl.statistical-language-model!⇒techNlplm,
    <a class="clsHide" href="#idTchInf006001lgmlnam"></a></p>

  <section id="idTchInf006001lgmlevg">
  <h3 id="idTchInf006001lgmlevgH3">evoluting of techNlplm
    <a class="clsHide" href="#idTchInf006001lgmlevgH3"></a></h3>
  <p id="idTchInf006001lgml2018">{2018}-techAi-LLM::
    <br>"Since 2018, large language models (LLMs) consisting of deep neural networks with billions of trainable parameters, trained on massive datasets of unlabelled text, have demonstrated impressive results on a wide variety of natural language processing tasks. This development has led to a shift in research focus toward the use of general-purpose LLMs."
    <br>[{2023-04-09 retrieved} https://en.wikipedia.org/wiki/Language_model]
    <br>* McsEngl.{2018}-techAi-LLM,
    <br>* McsEngl.{techInfo'2018}-techAi-LLM,
    <a class="clsHide" href="#idTchInf006001lgml2018"></a></p>
  </section>

  <section id="idTchInf006001lgmlspc">
  <h3 id="idTchInf006001lgmlspcH3">techNlplm.SPECIFIC
    <a class="clsHide" href="#idTchInf006001lgmlspcH3"></a></h3>
  <p id="idTchInf006001lgmlspcdsn">description::
    <br>* neural-language-model,
    <br>** large-neural-language-model,
    <br>** recurent-neural-language-model,
    <br>** feedforward-neural-language-model,
    <br>** transformer-neural-language-model,
    <br>* Markov-(n-gram)-language-model,
    <a class="clsHide" href="#idTchInf006001lgmlspcdsn"></a></p>
  <p id="idTchInf006001lgmlspcnam">name::
    <br>* McsEngl.techNlplm.specific,
    <a class="clsHide" href="#idTchInf006001lgmlspcnam"></a></p>
  </section>

  <section id="idTchInf006001lgmlNrl">
  <h3 id="idTchInf006001lgmlNrlH3">techNlplm.neural-language-model
    <a class="clsHide" href="#idTchInf006001lgmlNrlH3"></a></h3>
  <p id="idTchInf006001lgmlNrldsn">description::
    <br>"Neural language models (or continuous space language models) use continuous representations or embeddings of words to make their predictions.[10] These models make use of neural networks.
    <br>Continuous space embeddings help to alleviate the curse of dimensionality in language modeling: as language models are trained on larger and larger texts, the number of unique words (the vocabulary) increases.[a] The number of possible sequences of words increases exponentially with the size of the vocabulary, causing a data sparsity problem because of the exponentially many sequences. Thus, statistics are needed to properly estimate probabilities. Neural networks avoid this problem by representing words in a distributed way, as non-linear combinations of weights in a neural net.[11] An alternate description is that a neural net approximates the language function. The neural net architecture might be feed-forward or recurrent, and while the former is simpler the latter is more common."
    <br>[{2023-04-09 retrieved} https://en.wikipedia.org/wiki/Language_model#Neural_network]
    <a class="clsHide" href="#idTchInf006001lgmlNrldsn"></a></p>
  <p id="idTchInf006001lgmlNrlnam">name::
    <br>* McsEngl.neural-language-model,
    <br>* McsEngl.techNlplm.neural-language-model,
    <a class="clsHide" href="#idTchInf006001lgmlNrlnam"></a></p>
  </section>

  <section id="idTchInf006001lgmlLarge">
  <h3 id="idTchInf006001lgmlLargeH3">techNlplm.large-language-model
    <a class="clsHide" href="#idTchInf006001lgmlLargeH3"></a></h3>
  <p id="idTchInf006001lgmlLargedsn">description::
    <br>"A large language model (LLM) is a language model consisting of a neural network with many parameters (typically billions of weights or more), trained on large quantities of unlabelled text using self-supervised learning. LLMs emerged around 2018 and perform well at a wide variety of tasks. This has shifted the focus of natural language processing research away from the previous paradigm of training specialized supervised models for specific tasks.[1]
    <br>Properties
    <br>Though the term large language model has no formal definition, it often refers to deep learning models having a parameter count on the order of billions or more.[2] LLMs are general purpose models which excel at a wide range of tasks, as opposed to being trained for one specific task (such as sentiment analysis, named entity recognition, or mathematical reasoning).[1][3] The skill with which they accomplish tasks, and the range of tasks at which they are capable, seems to be a function of the amount of resources (data, parameter-size, computing power) devoted to them, in a way that is not dependent on additional breakthroughs in design.[4]
    <br>Though trained on simple tasks along the lines of predicting the next word in a sentence, neural language models with sufficient training and parameter counts are found to capture much of the syntax and semantics of human language. In addition, large language models demonstrate are able to "memorize" a great quantity of facts during training.[1] The ability of LLMs to often produce factually accurate responses can create the impression that they have general knowledge about the world; the production of responses with factual content that does not seem to be justified by the model's training data is referred to as a "hallucination".[5]"
    <br>[{2023-04-09 retrieved} https://en.wikipedia.org/wiki/Large_language_model]
    <a class="clsHide" href="#idTchInf006001lgmlLargedsn"></a></p>
  <p id="idTchInf006001lgmlLargenam">name::
    <br>* McsEngl.LLM-large-language-model!⇒techNlplmL,
    <br>* McsEngl.large-language-model!⇒techNlplmL,
    <br>* McsEngl.techNlplm.large-language-model!⇒techNlplmL,
    <br>* McsEngl.techNlplmL,
    <a class="clsHide" href="#idTchInf006001lgmlLargenam"></a></p>

  <section id="idTchInf006001lgmlLargeBloom">
  <h4 id="idTchInf006001lgmlLargeBloomH4">techNlplmL.BLOOM
    <a class="clsHide" href="#idTchInf006001lgmlLargeBloomH4"></a></h4>
  <p id="idTchInf006001lgmlLargeBloomdsn">description::
    <br>"BLOOM is an autoregressive Large Language Model (LLM), trained to continue text from a prompt on vast amounts of text data using industrial-scale computational resources. As such, it is able to output coherent text in 46 languages and 13 programming languages that is hardly distinguishable from text written by humans. BLOOM can also be instructed to perform text tasks it hasn't been explicitly trained for, by casting them as text generation tasks."
    <br>[{2023-04-09 retrieved} https://huggingface.co/bigscience/bloom]
    <a class="clsHide" href="#idTchInf006001lgmlLargeBloomdsn"></a></p>
  <p id="idTchInf006001lgmlLargeBloomnam">name::
    <br>* McsEngl.BLOOM,
    <br>* McsEngl.techNlplmL.BLOOM,
    <a class="clsHide" href="#idTchInf006001lgmlLargeBloomnam"></a></p>
  </section>
  </section>
  </section>

  <section id="idTchInf006001">
  <h2 id="idTchInf006001H2">techNlp.SPECIFIC
    <a class="clsHide" href="#idTchInf006001H2"></a></h2>
  <p id="idTchInf006001dsn">description::
    <br>* Natural-Language-Understanding,
    <br>* Natural-Language-Generation,
    <br>* <a class="clsPreview" href="#idTchInf008">Machine-learning</a>,
    <br>* <a class="clsPreview" href="#idTchInf006002">Machine-translation</a>,
    <br>* Grouping similar words,
    <br>* Finding words with the same meaning,
    <br>* Generating realistic names,
    <br>* Understanding how much time it takes to read a text,
    <br>* Understanding how difficult to read is a text,
    <br>* <a class="clsPreview" href="#idTchInf006001">Identifying the language of a text</a>,
    <br>* Generating a summary of a text,
    <br>* Finding similar documents,
    <br>* Identifying entities,
    <br>* Understanding the attitude expressed in a text,
    <br>* Translating a text,
    <br>* speech-to-text,
    <br>* text-to-speech,
    <br>* question answering,
    <br>* parsing,
    <br>* part-of-speech tagging,
    <br>* optical character recognition,
    <br>* handwriting recognition,
    <a class="clsHide" href="#idTchInf006001dsn"></a></p>
  <p id="idTchInf006001nam">name::
    <br>* McsEngl.techNlp.specific,
    <a class="clsHide" href="#idTchInf006001nam"></a></p>
  </section>

  <section id="idTchInf006001">
  <h2 id="idTchInf006001H2">techNlp.language-recognition
    <a class="clsHide" href="#idTchInf006001H2"></a></h2>
  <p id="idTchInf006001dsn">description::
    <br>· Identifying the language of a text.
    <a class="clsHide" href="#idTchInf006001dsn"></a></p>
  <p id="idTchInf006001nam">name::
    <br>* McsEngl.identifying-language-of-text,
    <br>* McsEngl.techNlp.001-language-recognition,
    <a class="clsHide" href="#idTchInf006001nam"></a></p>
  <p id="idTchInf006001wpa">addressWpg::
    <br>* https://en.wikipedia.org/wiki/Wikipedia:Language_recognition_chart,
    <a class="clsHide" href="#idTchInf006001wpa"></a></p>
  </section>

  <section id="idTchInf006002">
  <h2 id="idTchInf006002H2">techNlp.machine-translation
    <a class="clsHide" href="#idTchInf006002H2"></a></h2>
  <p id="idTchInf006002dsn">description::
    <br>"Machine translation, sometimes referred to by the abbreviation MT[1] (not to be confused with computer-aided translation, machine-aided human translation or interactive translation), is a sub-field of computational linguistics that investigates the use of software to translate text or speech from one language to another."
    <br>[{2021-02-06} https://en.wikipedia.org/wiki/Machine_translation]
    <a class="clsHide" href="#idTchInf006002dsn"></a></p>
  <p id="idTchInf006002nam">name::
    <br>* McsEngl.machine-translation-tech!⇒techMntn,
    <br>* McsEngl.techMntn,
    <br>* McsEngl.techMntn'(machine-translation)!⇒techMntn,
    <br>* McsEngl.techNlp.002-machine-translation!⇒techMntn,
    <br>* McsEngl.techNlp.machine-translation!⇒techMntn,
    <a class="clsHide" href="#idTchInf006002nam"></a></p>
  </section>

  <section id="idTchInf006003">
  <h2 id="idTchInf006003H2">techNlp.speech-recognition
    <a class="clsHide" href="#idTchInf006003H2"></a></h2>
  <p id="idTchInf006003dsn">description::
    <br>"Speech recognition is an interdisciplinary subfield of computer science and computational linguistics that develops methodologies and technologies that enable the recognition and translation of spoken language into text by computers with the main benefit of searchability. It is also known as automatic speech recognition (ASR), computer speech recognition or speech to text (STT). It incorporates knowledge and research in the computer science, linguistics and computer engineering fields. The reverse process is speech synthesis.
    <br>Some speech recognition systems require "training" (also called "enrollment") where an individual speaker reads text or isolated vocabulary into the system. The system analyzes the person's specific voice and uses it to fine-tune the recognition of that person's speech, resulting in increased accuracy. Systems that do not use training are called "speaker-independent"[1] systems. Systems that use training are called "speaker dependent".
    <br>Speech recognition applications include voice user interfaces such as voice dialing (e.g. "call home"), call routing (e.g. "I would like to make a collect call"), domotic appliance control, search key words (e.g. find a podcast where particular words were spoken), simple data entry (e.g., entering a credit card number), preparation of structured documents (e.g. a radiology report), determining speaker characteristics,[2] speech-to-text processing (e.g., word processors or emails), and aircraft (usually termed direct voice input).
    <br>The term voice recognition[3][4][5] or speaker identification[6][7][8] refers to identifying the speaker, rather than what they are saying. Recognizing the speaker can simplify the task of translating speech in systems that have been trained on a specific person's voice or it can be used to authenticate or verify the identity of a speaker as part of a security process.
    <br>From the technology perspective, speech recognition has a long history with several waves of major innovations. Most recently, the field has benefited from advances in deep learning and big data. The advances are evidenced not only by the surge of academic papers published in the field, but more importantly by the worldwide industry adoption of a variety of deep learning methods in designing and deploying speech recognition systems."
    <br>[{2023-04-02 retrieved} https://en.wikipedia.org/wiki/Speech_recognition]
    <a class="clsHide" href="#idTchInf006003dsn"></a></p>
  <p id="idTchInf006003nam">name::
    <br>* McsEngl.ASR-automatic-speech-recognition!⇒techSprc,
    <br>* McsEngl.STT-speech-to-text!⇒techSprc,
    <br>* McsEngl.automatic-speech-recognition!⇒techSprc,
    <br>* McsEngl.computer-speech-recognition!⇒techSprc,
    <br>* McsEngl.techNlp.003-speech-recognition!⇒techSprc,
    <br>* McsEngl.techNlp.speech-recognition!⇒techSprc,
    <br>* McsEngl.techSprc,
    <br>* McsEngl.speech-recognition!⇒techSprc,
    <br>* McsEngl.speech-to-text!⇒techSprc,
    <a class="clsHide" href="#idTchInf006003nam"></a></p>
  </section>

  <section id="idTchInf006004">
  <h2 id="idTchInf006004H2">techNlp.speech-synthesis
    <a class="clsHide" href="#idTchInf006004H2"></a></h2>
  <p id="idTchInf006004dsn">description::
    <br>"Speech synthesis is the artificial production of human speech. A computer system used for this purpose is called a speech synthesizer, and can be implemented in software or hardware products. A text-to-speech (TTS) system converts normal language text into speech; other systems render symbolic linguistic representations like phonetic transcriptions into speech.[1] The reverse process is speech recognition."
    <br>[{2023-04-02 retrieved} https://en.wikipedia.org/wiki/Speech_synthesis]
    <a class="clsHide" href="#idTchInf006004dsn"></a></p>
  <p id="idTchInf006004nam">name::
    <br>* McsEngl.TTS-text-to-speech!⇒techSpsn,
    <br>* McsEngl.techNlp.004-speech-synthesis!⇒techSpsn,
    <br>* McsEngl.techNlp.speech-synthesis!⇒techSpsn,
    <br>* McsEngl.techSpsn,
    <br>* McsEngl.text-to-speech!⇒techSpsn,
    <br>* McsEngl.speech-synthesis!⇒techSpsn,
    <a class="clsHide" href="#idTchInf006004nam"></a></p>
  </section>
</section>

<section id="idTchInf008">
  <h1 id="idTchInf008H1">techInfo.machine-learning-008
    <a class="clsHide" href="#idTchInf008H1"></a></h1>
  <p id="idTchInf008dsn">description::
    <br>"A machine learning algorithm is an algorithm that is able to learn from data.But what do we mean by learning? Mitchell (1997) provides a succinct deﬁnition:“A computer program is said to learn from experienceEwith respect to someclass of tasksTand performance measureP, if its performance at tasks inT, asmeasured byP, improves with experienceE.” "
    <br>[{2022-12-06 retrieved} https://www.deeplearningbook.org/contents/ml.html]
    <br>"A system is said to learn if it is capable of acquiring new knowledge from its environment.
    <br>Learning may also enable the ability to perform new tasks without having to be redesigned or reprogrammed, especially when accompanied by generalization.
    <br>Learning is most readily accomplished in a system that supports symbolic abstraction, though such a property is not exclusive (reinforcement strategies, for example, do not necessarily require symbolic representation).
    <br>This type of learning is separated from the acquisition of knowledge through direct programming by the designer, which is referred to throughout this document as the Ability to Add New Knowledge."
    [{1998-02-16} http://krusty.eecs.umich.edu/cogarch4/toc_defs/defs_capa/defs_lear.html]
    <a class="clsHide" href="#idTchInf008dsn"></a></p>
  <p id="idTchInf008nam">name::
    <br>* McsEngl.ML'(Machine-Learning)!⇒techMl,
    <br>* McsEngl.Machine-Learning!⇒techMl,
    <br>* McsEngl.techInfo.008-Machine-Learning!⇒techMl,
    <br>* McsEngl.techInfo.Machine-Learning!⇒techMl,
    <br>* McsEngl.techMl,
    <br>* McsEngl.techMachine-learning!⇒techMl,
    <a class="clsHide" href="#idTchInf008nam"></a></p>
  <p id="idTchInf008dsnL">descriptionLong::
    <br>"Machine learning (ML) is the study of computer algorithms that improve automatically through experience.[1][2] It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as "training data", in order to make predictions or decisions without being explicitly programmed to do so.[3] Machine learning algorithms are used in a wide variety of applications, such as email filtering and computer vision, where it is difficult or infeasible to develop conventional algorithms to perform the needed tasks.
    <br>Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a related field of study, focusing on exploratory data analysis through unsupervised learning.[5][6] In its application across business problems, machine learning is also referred to as predictive analytics."
    <br>[{2020-09-22} https://en.wikipedia.org/wiki/Machine_learning]
    <a class="clsHide" href="#idTchInf008dsnL"></a></p>

  <section id="idTchInf008engnr">
  <h2 id="idTchInf008engnrH2">engineer of techMl
    <a class="clsHide" href="#idTchInf008engnrH2"></a></h2>
  <p id="idTchInf008engnrdsn">description::
    <br>"A Machine Learning Engineer creates, edits, analyzes, debugs, models, and supervises the development of machine learning models using programming languages such as Python or C++ and machine learning libraries such as Keras or TensorFlow.
    <br>... The average annual income of a Machine Learning Engineer in the United States is between $112,000 and $157,000 with a median of $131,000 per year according to multiple data sources such as Indeed, Glassdoor, Salary.com, and Payscale."
    <br>[{2023-03-29 retrieved} https://blog.finxter.com/machine-learning-engineer-income-and-opportunity/]
    <a class="clsHide" href="#idTchInf008engnrdsn"></a></p>
  <p id="idTchInf008engnrnam">name::
    <br>* McsEngl.techMl'engineer,
    <a class="clsHide" href="#idTchInf008engnrnam"></a></p>
  </section>

  <section id="idTchInf008ozn">
  <h2 id="idTchInf008oznH2">organization of techMl
    <a class="clsHide" href="#idTchInf008oznH2"></a></h2>
  <p id="idTchInf008ozndsn">description::
    <br>* <a class="clsPreview" href="https://huggingface.co/">Hugging-Face</a>,
    <a class="clsHide" href="#idTchInf008ozndsn"></a></p>
  <p id="idTchInf008oznnam">name::
    <br>* McsEngl.techMl'organization,
    <a class="clsHide" href="#idTchInf008oznnam"></a></p>
  </section>

  <section id="idTchInf008rscF">
  <h2 id="idTchInf008rscFH2">info-resource of techMl
    <a class="clsHide" href="#idTchInf008rscFH2"></a></h2>
  <p id="idTchInf008rscFdsn">description::
    <br>* https://machinelearningmastery.com/,
    <a class="clsHide" href="#idTchInf008rscFdsn"></a></p>
  <p id="idTchInf008rscFnam">name::
    <br>* McsEngl.techMl'Infrsc,
    <a class="clsHide" href="#idTchInf008rscFnam"></a></p>
  </section>

  <section id="idTchInf008Spc">
  <h2 id="idTchInf008SpcH2">techMl.SPECIFIC
    <a class="clsHide" href="#idTchInf008SpcH2"></a></h2>
  <p id="idTchInf008Spcdsn">description::
    <br>* deep-learning,
    <br>* Supervised Learning (e.g., Linear Regression, Support Vector Machines)
    <br>* Unsupervised Learning (e.g., Clustering, Dimensionality Reduction)
    <br>* Reinforcement Learning (e.g., Q-Learning, Policy Gradient)
    <a class="clsHide" href="#idTchInf008Spcdsn"></a></p>
  <p id="idTchInf008Spcnam">name::
    <br>* McsEngl.techMl.specific,
    <a class="clsHide" href="#idTchInf008Spcnam"></a></p>
  </section>

  <section id="idTchInf008Dplr">
  <h2 id="idTchInf008DplrH2">techMl.deep-learning
    <a class="clsHide" href="#idTchInf008DplrH2"></a></h2>
  <p id="idTchInf008Dplrdsn">description::
    <br>"Deep learning is part of a broader family of machine learning methods based on artificial neural networks with representation learning. Learning can be supervised, semi-supervised or unsupervised.[2]
    <br>Deep-learning architectures such as deep neural networks, deep belief networks, deep reinforcement learning, recurrent neural networks, convolutional neural networks and transformers have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.[3][4][5]
    <br>Artificial neural networks (ANNs) were inspired by information processing and distributed communication nodes in biological systems. ANNs have various differences from biological brains. Specifically, artificial neural networks tend to be static and symbolic, while the biological brain of most living organisms is dynamic (plastic) and analog.[6][7]
    <br>The adjective "deep" in deep learning refers to the use of multiple layers in the network. Early work showed that a linear perceptron cannot be a universal classifier, but that a network with a nonpolynomial activation function with one hidden layer of unbounded width can. Deep learning is a modern variation that is concerned with an unbounded number of layers of bounded size, which permits practical application and optimized implementation, while retaining theoretical universality under mild conditions. In deep learning the layers are also permitted to be heterogeneous and to deviate widely from biologically informed connectionist models, for the sake of efficiency, trainability and understandability."
    <br>[{2023-04-01 retrieved} https://en.wikipedia.org/wiki/Deep_learning#]
    <a class="clsHide" href="#idTchInf008Dplrdsn"></a></p>
  <p id="idTchInf008Dplrnam">name::
    <br>* McsEngl.Deep-Learning!⇒techMlDl,
    <br>* McsEngl.techMlDl,
    <a class="clsHide" href="#idTchInf008Dplrnam"></a></p>

  <section id="idTchInf008DplrSpc">
  <h3 id="idTchInf008DplrSpcH3">techMlDl.SPECIFIC
    <a class="clsHide" href="#idTchInf008DplrSpcH3"></a></h3>
  <p id="idTchInf008DplrSpcdsn">description::
    <br>* deep neural networks,
    <br>* deep belief networks,
    <br>* deep reinforcement learning,
    <br>* recurrent neural networks,
    <br>* convolutional neural networks,
    <br>* transformers,
    <a class="clsHide" href="#idTchInf008DplrSpcdsn"></a></p>
  <p id="idTchInf008DplrSpcnam">name::
    <br>* McsEngl.techMlDl.specific,
    <a class="clsHide" href="#idTchInf008DplrSpcnam"></a></p>
  </section>
  </section>

  <section id="idTchInf008Spvd">
  <h2 id="idTchInf008SpvdH2">techMl.supervised-learning
    <a class="clsHide" href="#idTchInf008SpvdH2"></a></h2>
  <p id="idTchInf008Spvddsn">description::
    <br>"Supervised learning (SL) is a machine learning paradigm for problems where the available data consists of labeled examples, meaning that each data point contains features (covariates) and an associated label. The goal of supervised learning algorithms is learning a function that maps feature vectors (inputs) to labels (output), based on example input-output pairs.[1] It infers a function from labeled training data consisting of a set of training examples.[2] In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal). A supervised learning algorithm analyzes the training data and produces an inferred function, which can be used for mapping new examples. An optimal scenario will allow for the algorithm to correctly determine the class labels for unseen instances. This requires the learning algorithm to generalize from the training data to unseen situations in a "reasonable" way (see inductive bias). This statistical quality of an algorithm is measured through the so-called generalization error."
    <br>[{2023-04-04 retrieved} https://en.wikipedia.org/wiki/Supervised_learning]
    <a class="clsHide" href="#idTchInf008Spvddsn"></a></p>
  <p id="idTchInf008Spvdnam">name::
    <br>* McsEngl.techMl.supervised-learning,
    <br>* McsEngl.supervised-learning,
    <a class="clsHide" href="#idTchInf008Spvdnam"></a></p>
  </section>

  <section id="idTchInf008Uspd">
  <h2 id="idTchInf008UspdH2">techMl.unsupervised-learning
    <a class="clsHide" href="#idTchInf008UspdH2"></a></h2>
  <p id="idTchInf008Uspddsn">description::
    <br>"Unsupervised learning is a type of algorithm that learns patterns from untagged data. The goal is that through mimicry, which is an important mode of learning in people, the machine is forced to build a concise representation of its world and then generate imaginative content from it.
    <br>In contrast to supervised learning where data is tagged by an expert, e.g. tagged as a "ball" or "fish", unsupervised methods exhibit self-organization that captures patterns as probability densities[1] or a combination of neural feature preferences encoded in the machine's weights and activations. The other levels in the supervision spectrum are reinforcement learning where the machine is given only a numerical performance score as guidance, and semi-supervised learning where a small portion of the data is tagged."
    <br>[{2023-04-04 retrieved} https://en.wikipedia.org/wiki/Unsupervised_learning#]
    <a class="clsHide" href="#idTchInf008Uspddsn"></a></p>
  <p id="idTchInf008Uspdnam">name::
    <br>* McsEngl.techMl.unsupervised-learning,
    <br>* McsEngl.unsupervised-learning,
    <a class="clsHide" href="#idTchInf008Uspdnam"></a></p>
  </section>

  <section id="idTchInf008Sspd">
  <h2 id="idTchInf008SspdH2">techMl.semisupervised-learning
    <a class="clsHide" href="#idTchInf008SspdH2"></a></h2>
  <p id="idTchInf008Sspddsn">description::
    <br>"Weak supervision, also called semi-supervised learning, is a branch of machine learning that combines a small amount of labeled data with a large amount of unlabeled data during training. Semi-supervised learning falls between unsupervised learning (with no labeled training data) and supervised learning (with only labeled training data). Semi-supervised learning aims to alleviate the issue of having limited amounts of labeled data available for training.
    <br>Semi-supervised learning is motivated by problem settings where unlabeled data is abundant and obtaining labeled data is expensive. Other branches of machine learning that share the same motivation but follow different assumptions and methodologies are active learning and weak supervision. Unlabeled data, when used in conjunction with a small amount of labeled data, can produce considerable improvement in learning accuracy. The acquisition of labeled data for a learning problem often requires a skilled human agent (e.g. to transcribe an audio segment) or a physical experiment (e.g. determining the 3D structure of a protein or determining whether there is oil at a particular location). The cost associated with the labeling process thus may render large, fully labeled training sets infeasible, whereas acquisition of unlabeled data is relatively inexpensive. In such situations, semi-supervised learning can be of great practical value. Semi-supervised learning is also of theoretical interest in machine learning and as a model for human learning."
    <br>[{2023-04-04 retrieved} https://en.wikipedia.org/wiki/Weak_supervision#Semi-supervised_learning]
    <a class="clsHide" href="#idTchInf008Sspddsn"></a></p>
  <p id="idTchInf008Sspdnam">name::
    <br>* McsEngl.semisupervised-learning,
    <br>* McsEngl.techMl.semisupervised-learning,
    <br>* McsEngl.weak-semisupervised-learning,
    <a class="clsHide" href="#idTchInf008Sspdnam"></a></p>
  </section>

  <section id="idTchInf008Rfmt">
  <h2 id="idTchInf008RfmtH2">techMl.reinforcement-learning
    <a class="clsHide" href="#idTchInf008RfmtH2"></a></h2>
  <p id="idTchInf008Rfmtdsn">description::
    <br>"Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.
    <br>Reinforcement learning differs from supervised learning in not needing labelled input/output pairs to be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).[1]
    <br>The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques.[2] The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible."
    <br>[{2023-04-04 retrieved} https://en.wikipedia.org/wiki/Reinforcement_learning]
    <br>===
    <br>"Reinforcement learning (RL) is learning by interacting with an environment. An RL agent learns from the consequences of its actions, rather than from being explicitly taught and it selects its actions on basis of its past experiences (exploitation) and also by new choices (exploration), which is essentially trial and error learning. The reinforcement signal that the RL-agent receives is a numerical reward, which encodes the success of an action's outcome, and the agent seeks to learn to select actions that maximize the accumulated reward over time. (The use of the term reward is used here in a neutral fashion and does not imply any pleasure, hedonic impact or other psychological interpretations.)"
    <br>[{2023-04-05 retrieved} http://www.scholarpedia.org/article/Reinforcement_learning]
    <a class="clsHide" href="#idTchInf008Rfmtdsn"></a></p>
  <p id="idTchInf008Rfmtnam">name::
    <br>* McsEngl.reinforecment-learning,
    <br>* McsEngl.techMl.reinforecment-learning,
    <a class="clsHide" href="#idTchInf008Rfmtnam"></a></p>
  </section>
</section>

<section id="idTchInf016">
  <h1 id="idTchInf016H1">techInfo.machine-reasoning-016
    <a class="clsHide" href="#idTchInf016H1"></a></h1>
  <p id="idTchInf016dsn">description::
    <br>"In computer science, in particular in knowledge representation and reasoning and metalogic, the area of automated reasoning is dedicated to understanding different aspects of reasoning. The study of automated reasoning helps produce computer programs that allow computers to reason completely, or nearly completely, automatically. Although automated reasoning is considered a sub-field of artificial intelligence, it also has connections with theoretical computer science and philosophy.
    <br>The most developed subareas of automated reasoning are automated theorem proving (and the less automated but more pragmatic subfield of interactive theorem proving) and automated proof checking (viewed as guaranteed correct reasoning under fixed assumptions).[citation needed] Extensive work has also been done in reasoning by analogy using induction and abduction.[1]
    <br>Other important topics include reasoning under uncertainty and non-monotonic reasoning. An important part of the uncertainty field is that of argumentation, where further constraints of minimality and consistency are applied on top of the more standard automated deduction. John Pollock's OSCAR system[2] is an example of an automated argumentation system that is more specific than being just an automated theorem prover.
    <br>Tools and techniques of automated reasoning include the classical logics and calculi, fuzzy logic, Bayesian inference, reasoning with maximal entropy and many less formal ad hoc techniques."
    <br>[{2023-04-03 retrieved} https://en.wikipedia.org/wiki/Automated_reasoning]
    <a class="clsHide" href="#idTchInf016dsn"></a></p>
  <p id="idTchInf016nam">name::
    <br>* McsEngl.automated-reasoning!⇒techMr,
    <br>* McsEngl.machine-reasoning!⇒techMr,
    <br>* McsEngl.techInfo.016-machine-reasoning!⇒techMr,
    <br>* McsEngl.techMr,
    <br>====== langoGreek:
    <br>* McsElln.μηχανικός-συλλογισμός,
    <a class="clsHide" href="#idTchInf016nam"></a></p>
</section>

<section id="idTchInf010">
  <h1 id="idTchInf010H1">techInfo.computer-vision-010
    <a class="clsHide" href="#idTchInf010H1"></a></h1>
  <p id="idTchInf010dsn">description::
    <br>"Computer vision tasks include methods for acquiring, processing, analyzing and understanding digital images, and extraction of high-dimensional data from the real world in order to produce numerical or symbolic information, e.g. in the forms of decisions.[1][2][3][4] Understanding in this context means the transformation of visual images (the input of the retina) into descriptions of the world that make sense to thought processes and can elicit appropriate action. This image understanding can be seen as the disentangling of symbolic information from image data using models constructed with the aid of geometry, physics, statistics, and learning theory.
    <br>The scientific discipline of computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, multi-dimensional data from a 3D scanner, or medical scanning devices. The technological discipline of computer vision seeks to apply its theories and models to the construction of computer vision systems.
    <br>Sub-domains of computer vision include scene reconstruction, object detection, event detection, video tracking, object recognition, 3D pose estimation, learning, indexing, motion estimation, visual servoing, 3D scene modeling, image generation, and image restoration.
    <br>Adopting computer vision technology might be painstaking for organizations as there is no single point solution for it. There are very few companies that provide a unified and distributed platform or an Operating System where computer vision applications can be easily deployed and managed."
    <br>[{2023-03-31 retrieved} https://en.wikipedia.org/wiki/Computer_vision#]
    <a class="clsHide" href="#idTchInf010dsn"></a></p>
  <p id="idTchInf010nam">name::
    <br>* McsEngl.computer-vision!⇒techCmrv,
    <br>* McsEngl.techInfo.010-computer-vision!⇒techCmrv,
    <br>* McsEngl.techInfo.computer-vision!⇒techCmrv,
    <a class="clsHide" href="#idTchInf010nam"></a></p>
</section>

<section id="idTchInf009">
  <h1 id="idTchInf009H1">techInfo.Artificial-Neural-Network-009
    <a class="clsHide" href="#idTchInf009H1"></a></h1>
  <p id="idTchInf009dsn">description::
    <br>"Artificial neural networks (ANNs), usually simply called neural networks (NNs) or neural nets,[1] are computing systems inspired by the biological neural networks that constitute animal brains.[2]
    <br>An ANN is based on a collection of connected units or nodes called artificial neurons, which loosely model the neurons in a biological brain. Each connection, like the synapses in a biological brain, can transmit a signal to other neurons. An artificial neuron receives signals then processes them and can signal neurons connected to it. The "signal" at a connection is a real number, and the output of each neuron is computed by some non-linear function of the sum of its inputs. The connections are called edges. Neurons and edges typically have a weight that adjusts as learning proceeds. The weight increases or decreases the strength of the signal at a connection. Neurons may have a threshold such that a signal is sent only if the aggregate signal crosses that threshold.
    <br>Typically, neurons are aggregated into layers. Different layers may perform different transformations on their inputs. Signals travel from the first layer (the input layer), to the last layer (the output layer), possibly after traversing the layers multiple times."
    <br>[{2023-03-29 retrieved} https://en.wikipedia.org/wiki/Artificial_neural_network]
    <a class="clsHide" href="#idTchInf009dsn"></a></p>
  <p id="idTchInf009nam">name::
    <br>* McsEngl.ANN!⇒techNn,
    <br>* McsEngl.Artificial-Neural-Network!⇒techNn,
    <br>* McsEngl.Neural-Network!⇒techNn,
    <br>* McsEngl.techInfo.009-Artificial-Neural-Network!⇒techNn,
    <br>* McsEngl.techNn,
    <a class="clsHide" href="#idTchInf009nam"></a></p>

  <section id="idTchInf009nurn">
  <h2 id="idTchInf009nurnH2">artificial-neuron of techNn
    <a class="clsHide" href="#idTchInf009nurnH2"></a></h2>
  <p id="idTchInf009nurndsn">description::
    <br>"An artificial neuron is a mathematical function conceived as a model of biological neurons, a neural network. Artificial neurons are elementary units in an artificial neural network.[1] The artificial neuron receives one or more inputs (representing excitatory postsynaptic potentials and inhibitory postsynaptic potentials at neural dendrites) and sums them to produce an output (or activation, representing a neuron's action potential which is transmitted along its axon). Usually each input is separately weighted, and the sum is passed through a non-linear function known as an activation function or transfer function[clarification needed]. The transfer functions usually have a sigmoid shape, but they may also take the form of other non-linear functions, piecewise linear functions, or step functions. They are also often monotonically increasing, continuous, differentiable and bounded. Non-monotonic, unbounded and oscillating activation functions with multiple zeros that outperform sigmoidal and ReLU like activation functions on many tasks have also been recently explored. The thresholding function has inspired building logic gates referred to as threshold logic; applicable to building logic circuits resembling brain processing. For example, new devices such as memristors have been extensively used to develop such logic in recent times.[2]
    <br>The artificial neuron transfer function should not be confused with a linear system's transfer function.
    <br>Artificial neurons can also refer to artificial cells in neuromorphic engineering (see below) that are similar to natural physical neurons."
    <br>[{2023-04-05 retrieved} https://en.wikipedia.org/wiki/Artificial_neuron]
    <br>· syntheticNo-neuron is <a class="clsPreview" href="../dirNtr/McsNtr000010.last.html#idBrnBioatt002NtrN">a-naturalNo-neuronBio</a> that DOES NOT look like a-natural-neuron.
    <a class="clsHide" href="#idTchInf009nurndsn"></a></p>
  <p id="idTchInf009nurnnam">name::
    <br>* McsEngl.artificial-neuron,
    <br>* McsEngl.neuronBio.syntheticNo,
    <br>* McsEngl.techNn'neuron,
    <a class="clsHide" href="#idTchInf009nurnnam"></a></p>
  </section>

  <section id="idTchInf009appl">
  <h2 id="idTchInf009applH2">application of techNn
    <a class="clsHide" href="#idTchInf009applH2"></a></h2>
  <p id="idTchInf009appldsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf009appldsn"></a></p>
  <p id="idTchInf009applnam">name::
    <br>* McsEngl.techNn'application,
    <a class="clsHide" href="#idTchInf009applnam"></a></p>
  </section>

  <section id="idTchInf009lbr">
  <h2 id="idTchInf009lbrH2">library of techNn
    <a class="clsHide" href="#idTchInf009lbrH2"></a></h2>
  <p id="idTchInf009lbrdsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf009lbrdsn"></a></p>
  <p id="idTchInf009lbrnam">name::
    <br>* McsEngl.techNn'framework,
    <br>* McsEngl.techNn'library,
    <a class="clsHide" href="#idTchInf009lbrnam"></a></p>
  </section>

  <section id="idTchInf009eval">
  <h2 id="idTchInf009evalH2">evaluation of techNn
    <a class="clsHide" href="#idTchInf009evalH2"></a></h2>
  <p id="idTchInf009evaldsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf009evaldsn"></a></p>
  <p id="idTchInf009evalnam">name::
    <br>* McsEngl.techNn'evaluation,
    <a class="clsHide" href="#idTchInf009evalnam"></a></p>
  </section>

  <section id="idTchInf009rsc">
  <h2 id="idTchInf009rscH2">info-resource of techNn
    <a class="clsHide" href="#idTchInf009rscH2"></a></h2>
  <p id="idTchInf009rscdsn">description::
    <br>·
    <a class="clsHide" href="#idTchInf009rscdsn"></a></p>
  <p id="idTchInf009rscnam">name::
    <br>* McsEngl.techNn'Infrsc,
    <a class="clsHide" href="#idTchInf009rscnam"></a></p>
  </section>

  <section id="idTchInf009Spc">
  <h2 id="idTchInf009SpcH2">techNn.SPECIFIC
    <a class="clsHide" href="#idTchInf009SpcH2"></a></h2>
  <p id="idTchInf009Spcdsn">description::
    <br>* convolutional-neural-network,
    <br>* feedforward-neural-network,
    <br>* long-short-term-memory-neural-network,
    <br>* recurrent-neural-network,
    <br>* recursive-neural-network,
    <br>* transformer-neural-network,
    <a class="clsHide" href="#idTchInf009Spcdsn"></a></p>
  <p id="idTchInf009Spcnam">name::
    <br>* McsEngl.techNn.specific,
    <a class="clsHide" href="#idTchInf009Spcnam"></a></p>
  </section>

  <section id="idTchInf009Fdfd">
  <h2 id="idTchInf009FdfdH2">techNn.feedforward
    <a class="clsHide" href="#idTchInf009FdfdH2"></a></h2>
  <p id="idTchInf009Fdfddsn">description::
    <br>"A feedforward neural network (FNN) is an artificial neural network wherein connections between the nodes do not form a cycle.[1] As such, it is different from its descendant: recurrent neural networks.
    <br>The feedforward neural network was the first and simplest type of artificial neural network devised.[2] In this network, the information moves in only one direction—forward—from the input nodes, through the hidden nodes (if any) and to the output nodes. There are no cycles or loops in the network."
    <br>[{2023-04-05 retrieved} https://en.wikipedia.org/wiki/Feedforward_neural_network]
    <a class="clsHide" href="#idTchInf009Fdfddsn"></a></p>
  <p id="idTchInf009Fdfdnam">name::
    <br>* McsEngl.FNN-feedforward-neural-network,
    <br>* McsEngl.feedforward-neural-network,
    <br>* McsEngl.techNn.feedforward,
    <a class="clsHide" href="#idTchInf009Fdfdnam"></a></p>
  </section>

  <section id="idTchInf009Lstm">
  <h2 id="idTchInf009LstmH2">techNn.long-short-term-memory
    <a class="clsHide" href="#idTchInf009LstmH2"></a></h2>
  <p id="idTchInf009Lstmdsn">description::
    <br>"Long short-term memory (LSTM)[1] is an artificial neural network used in the fields of artificial intelligence and deep learning. Unlike standard feedforward neural networks, LSTM has feedback connections. Such a recurrent neural network (RNN) can process not only single data points (such as images), but also entire sequences of data (such as speech or video). This characteristic makes LSTM networks ideal for processing and predicting data. For example, LSTM is applicable to tasks such as unsegmented, connected handwriting recognition,[2] speech recognition,[3][4] machine translation,[5][6] speech activity detection,[7] robot control,[8][9] video games,[10][11] and healthcare.[12]
    <br>The name of LSTM refers to the analogy that a standard RNN has both "long-term memory" and "short-term memory". The connection weights and biases in the network change once per episode of training, analogous to how physiological changes in synaptic strengths store long-term memories; the activation patterns in the network change once per time-step, analogous to how the moment-to-moment change in electric firing patterns in the brain store short-term memories.[13] The LSTM architecture aims to provide a short-term memory for RNN that can last thousands of timesteps, thus "long short-term memory".[1]
    <br>A common LSTM unit is composed of a cell, an input gate, an output gate[14] and a forget gate.[15] The cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell. Forget gates decide what information to discard from a previous state by assigning a previous state, compared to a current input, a value between 0 and 1. A (rounded) value of 1 means to keep the information, and a value of 0 means to discard it. Input gates decide which pieces of new information to store in the current state, using the same system as forget gates. Output gates control which pieces of information in the current state to output by assigning a value from 0 to 1 to the information, considering the previous and current states. Selectively outputting relevant information from the current state allows the LSTM network to maintain useful, long-term dependencies to make predictions, both in current and future time-steps.
    <br>LSTM networks are well-suited to classifying, processing and making predictions based on time series data, since there can be lags of unknown duration between important events in a time series. LSTMs were developed to deal with the vanishing gradient problem[16] that can be encountered when training traditional RNNs. Relative insensitivity to gap length is an advantage of LSTM over RNNs, hidden Markov models and other sequence learning methods in numerous applications."
    <br>[{2023-04-02 retrieved} https://en.wikipedia.org/wiki/Long_short-term_memory]
    <a class="clsHide" href="#idTchInf009Lstmdsn"></a></p>
  <p id="idTchInf009Lstmnam">name::
    <br>* McsEngl.LSTM-long-short-term-memory!⇒techLstm,
    <br>* McsEngl.long-short-term-memory!⇒techLstm,
    <br>* McsEngl.techLstm,
    <br>* McsEngl.techNn.long-short-term-memory!⇒techLstm,
    <a class="clsHide" href="#idTchInf009Lstmnam"></a></p>
  </section>

  <section id="idTchInf009Rnn">
  <h2 id="idTchInf009RnnH2">techNn.recurrent
    <a class="clsHide" href="#idTchInf009RnnH2"></a></h2>
  <p id="idTchInf009Rnndsn">description::
    <br>"A recurrent neural network (RNN) is a class of artificial neural networks where connections between nodes can create a cycle, allowing output from some nodes to affect subsequent input to the same nodes. This allows it to exhibit temporal dynamic behavior. Derived from feedforward neural networks, RNNs can use their internal state (memory) to process variable length sequences of inputs.[1][2][3] This makes them applicable to tasks such as unsegmented, connected handwriting recognition[4] or speech recognition.[5][6] Recurrent neural networks are theoretically Turing complete and can run arbitrary programs to process arbitrary sequences of inputs.[7]
    <br>The term "recurrent neural network" is used to refer to the class of networks with an infinite impulse response, whereas "convolutional neural network" refers to the class of finite impulse response. Both classes of networks exhibit temporal dynamic behavior.[8] A finite impulse recurrent network is a directed acyclic graph that can be unrolled and replaced with a strictly feedforward neural network, while an infinite impulse recurrent network is a directed cyclic graph that can not be unrolled.
    <br>Both finite impulse and infinite impulse recurrent networks can have additional stored states, and the storage can be under direct control by the neural network. The storage can also be replaced by another network or graph if that incorporates time delays or has feedback loops. Such controlled states are referred to as gated state or gated memory, and are part of long short-term memory networks (LSTMs) and gated recurrent units. This is also called Feedback Neural Network (FNN)."
    <br>[{2023-04-02 retrieved} https://en.wikipedia.org/wiki/Recurrent_neural_network]
    <a class="clsHide" href="#idTchInf009Rnndsn"></a></p>
  <p id="idTchInf009Rnnnam">name::
    <br>* McsEngl.RNN-recurrent-neural-network!⇒techRnn,
    <br>* McsEngl.recurrent-neural-network!⇒techRnn,
    <br>* McsEngl.techNn.recurrent!⇒techRnn,
    <br>* McsEngl.techRnn,
    <a class="clsHide" href="#idTchInf009Rnnnam"></a></p>
  </section>
</section>

<section id="idTchInf011">
  <h1 id="idTchInf011H1">techInfo.transformer-011
    <a class="clsHide" href="#idTchInf011H1"></a></h1>
  <p id="idTchInf011dsn">description::
    <br>"A transformer is a deep learning model that adopts the mechanism of self-attention, differentially weighting the significance of each part of the input data. It is used primarily in the fields of natural language processing (NLP)[1] and computer vision (CV).[2]
    <br>Like recurrent neural networks (RNNs), transformers are designed to process sequential input data, such as natural language, with applications towards tasks such as translation and text summarization. However, unlike RNNs, transformers process the entire input all at once. The attention mechanism provides context for any position in the input sequence. For example, if the input data is a natural language sentence, the transformer does not have to process one word at a time. This allows for more parallelization than RNNs and therefore reduces training times.[1]
    <br>Transformers were introduced in 2017 by a team at Google Brain[1] and are increasingly becoming the model of choice for NLP problems,[3] replacing RNN models such as long short-term memory (LSTM). The additional training parallelization allows training on larger datasets. This led to the development of pretrained systems such as BERT (Bidirectional Encoder Representations from Transformers) and GPT (Generative Pre-trained Transformer), which were trained with large language datasets, such as the Wikipedia Corpus and Common Crawl, and can be fine-tuned for specific tasks."
    <br>[{2023-04-01 retrieved} https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)]
    <a class="clsHide" href="#idTchInf011dsn"></a></p>
  <p id="idTchInf011nam">name::
    <br>* McsEngl.techInfo.011-transformer!⇒techTrfr,
    <br>* McsEngl.techInfo.transformer!⇒techTrfr,
    <br>* McsEngl.techTrfr,
    <br>* McsEngl.transformer!⇒techTrfr,
    <a class="clsHide" href="#idTchInf011nam"></a></p>

  <section id="idTchInf011eval">
  <h2 id="idTchInf011evalH2">evaluation of techTrfr
    <a class="clsHide" href="#idTchInf011evalH2"></a></h2>

  <section id="idTchInf011crtm">
  <h3 id="idTchInf011crtmH3">criticism of techTrfr
    <a class="clsHide" href="#idTchInf011crtmH3"></a></h3>
  <p id="idTchInf011crtmdsn">description::
    <br>"While Transformer models have been very successful in natural language processing tasks, there are some criticisms of the architecture and its use.
    <br>* Over-reliance on large amounts of data: Transformer models require large amounts of data for training, which can be difficult to obtain for some languages or domains. This can lead to biases in the model and limit its generalization ability.
    <br>* Interpretability: Transformer models can be difficult to interpret, which can make it challenging to understand how they arrive at their predictions. This is particularly important in applications where it is necessary to understand the reasoning behind the model's decisions.
    <br>* High computational requirements: Training and using Transformer models can be computationally expensive, which can limit their accessibility and use in resource-constrained environments.
    <br>* Lack of long-term understanding: While Transformer models are very good at understanding short-term relationships between words, they can struggle with long-term dependencies. This can make it difficult to generate coherent and meaningful text over longer sequences.
    <br>* Fairness and bias: Transformer models can inherit biases from the training data, which can lead to unfair and discriminatory outcomes in some applications. This is a particularly important concern in applications such as hiring, lending, and criminal justice.
    <br>* Carbon footprint: Training large Transformer models can consume a significant amount of energy, which can contribute to greenhouse gas emissions and exacerbate climate change.
    <br>These criticisms highlight some of the challenges and limitations of Transformer models and the need to carefully consider their use in different applications."
    <br>[{2023-04-10 retrieved} https://chat.openai.com/chat]
    <a class="clsHide" href="#idTchInf011crtmdsn"></a></p>
  <p id="idTchInf011crtmnam">name::
    <br>* McsEngl.techTrfr'criticism,
    <a class="clsHide" href="#idTchInf011crtmnam"></a></p>
  </section>
  </section>

  <section id="idTchInf011Spc">
  <h2 id="idTchInf011SpcH2">techTrfr.SPECIFIC
    <a class="clsHide" href="#idTchInf011SpcH2"></a></h2>
  <p id="idTchInf011Spcdsn">description::
    <br>* BERT,
    <br>* GPT,
    <br>* WuDao,
    <a class="clsHide" href="#idTchInf011Spcdsn"></a></p>
  <p id="idTchInf011Spcnam">name::
    <br>* McsEngl.techTrfr.specific,
    <a class="clsHide" href="#idTchInf011Spcnam"></a></p>
  </section>

  <section id="idTchInf011Bert">
  <h2 id="idTchInf011BertH2">techTrfr.BERT
    <a class="clsHide" href="#idTchInf011BertH2"></a></h2>
  <p id="idTchInf011Bertdsn">description::
    <br>"BERT (Bidirectional Encoder Representations from Transformers) is a pre-trained language model developed by Google in 2018. It is based on the transformer architecture and uses a large corpus of text to learn general language representations. BERT is trained in an unsupervised manner on a massive amount of text data and can be fine-tuned on various downstream natural language processing tasks such as question answering, text classification, and named entity recognition.
    <br>BERT uses a bidirectional approach, meaning that it takes into account the context of both preceding and following words in a sentence to generate word representations. This approach improves the ability of the model to capture the meaning of words in context, leading to better performance on downstream tasks. BERT also introduced a novel technique called "masked language modeling" where it randomly masks some words in the input sentence and then tries to predict the masked words based on the context.
    <br>Since its introduction, BERT has become one of the most widely used language models in the natural language processing community due to its state-of-the-art performance on many benchmark tasks. Its success has also led to the development of many variants and extensions, such as RoBERTa, ALBERT, and DistilBERT."
    <br>[{2023-04-09 retrieved} https://chat.openai.com/chat]
    <a class="clsHide" href="#idTchInf011Bertdsn"></a></p>
  <p id="idTchInf011Bertnam">name::
    <br>* McsEngl.BERT,
    <br>* McsEngl.Bidirectional-Encoder-Representations-from-Transformers,
    <br>* McsEngl.techTrfr.BERT,
    <a class="clsHide" href="#idTchInf011Bertnam"></a></p>
  </section>

  <section id="idTchInf011Gpt">
  <h2 id="idTchInf011GptH2">techTrfr.GPT
    <a class="clsHide" href="#idTchInf011GptH2"></a></h2>
  <p id="idTchInf011Gptdsn">description::
    <br>"Generative pre-trained transformers (GPT) are a family of large language models (LLMs)[1], which was introduced in 2018 by the American artificial intelligence organization OpenAI.[2] GPT models are artificial neural networks that are based on the transformer architecture, pre-trained on large datasets of unlabelled text, and able to generate novel human-like text.[3] At this point, most LLMs have these characteristics.
    <br>Between 2018 and 2023, OpenAI released four major numbered GPT models, with each new release being significantly more capable than the previous, due to increased size (measured in number of trainable parameters) and training. The largest GPT-3 models, released in 2020, have 175 billion parameters and were trained on 400 billion tokens of text.[4] OpenAI declined to publish the size or training details of its most recent model, GPT-4, citing "the competitive landscape and the safety implications of large-scale models".[5] OpenAI has been using these foundational GPT-n models as the basis for various other products and technologies, including models fine-tuned for instruction following, which in turn power the ChatGPT chatbot service.
    <br>The term "GPT" is also used in the names of some generative LLMs developed by others, such as a series of GPT-3 inspired models created by EleutherAI,[6] and most recently a series of seven models created by Cerebras.[7] Major companies in other industries (e.g. sales, finance) also use the term "GPT" in the names of their services involving or utilizing a GPT technology.[8][9]"
    <br>[{2023-04-09 retrieved} https://en.wikipedia.org/wiki/Generative_pre-trained_transformer]
    <a class="clsHide" href="#idTchInf011Gptdsn"></a></p>
  <p id="idTchInf011Gptnam">name::
    <br>* McsEngl.GPT!⇒techGpt,
    <br>* McsEngl.techGpt,
    <br>* McsEngl.techTrfr.GPT!⇒techGpt,
    <a class="clsHide" href="#idTchInf011Gptnam"></a></p>
  </section>

  <section id="idTchInf011Wudao">
  <h2 id="idTchInf011WudaoH2">techTrfr.WuDao
    <a class="clsHide" href="#idTchInf011WudaoH2"></a></h2>
  <p id="idTchInf011Wudaodsn">description::
    <br>"WuDao is the world largest pre-trained language model to date. The model was trained with FastMoE, a Fast Mixture-of-Expert (MoE) training system developed by BAAI itself, on 1.75 trillion parameters."
    <br>[{2023-04-09 retrieved} https://www.baai.ac.cn/english.html]
    <a class="clsHide" href="#idTchInf011Wudaodsn"></a></p>
  <p id="idTchInf011Wudaonam">name::
    <br>* McsEngl.WuDao,
    <br>* McsEngl.techTrfr.WuDao,
    <a class="clsHide" href="#idTchInf011Wudaonam"></a></p>
  </section>
</section>

<section id="idMeta">
  <h1 id="idMetaH1">meta-info
    <a class="clsHide" href="#idMetaH1"></a></h1>
  <p id="idMetaCounter" class="clsCenter">this webpage was-visited
    <span class="clsColorRed">
    <script src="../../dirPgm/dirCntr/counter.php?page=McsTchInf000002"></script>
    </span>
    times since {2019-12-28}</p>
  <!-- the content of page-path paragraph is displayed as it is on top of toc -->
  <p id="idMetaWebpage_path"><span class="clsB clsColorGreen">page-wholepath</span>:
    <a class="clsPreview" href="../../#idOverview">synagonism.net</a> /
    <a class="clsPreview" href="../Mcs000000.last.html#idOverview">worldviewSngo</a> /
    <a class="clsPreview" href="McsTchInf000000.last.html#idOverview">dirTchInf</a> /
    techInfo
    </p>
  <p id="idMetaP1">SEARCH::
    <br>· this page uses '<span class="clsColorRed">locator-names</span>', names that when you find them, you find the-LOCATION of the-concept they denote.
    <br>⊛ <strong>GLOBAL-SEARCH</strong>:
    <br>· clicking on <span class="clsColorGreenBg">the-green-BAR of a-page</span> you have access to the-global--locator-names of my-site.
    <br>· use the-prefix '<span class="clsColorRed">techInfo</span>' for <a class="clsPreview" href="../dirCor/McsCor000002.last.html#idOverview">sensorial-concepts</a> related to current concept 'information-technology'.
    <br>⊛ <strong>LOCAL-SEARCH</strong>:
    <br>· TYPE <span class="clsColorRed">CTRL+F "McsLang.words-of-concept's-name"</span>, to go to the-LOCATION of the-concept.
    <br>· a-preview of the-description of a-global-name makes reading fast.
    <a class="clsHide" href="#idMetaP1"></a></p>
  <p id="idFooterP1">footer::
    <br>• author: <a class="clsPreview" href="../dirHmn/McsHmn000003.last.html#idOverview">Kaseluris.Nikos.1959</a>
    <br>• email:
    <br> &nbsp;<img src="../../dirRsc/dirImg/mail.png">
    <br>• edit on github: https://github.com/synagonism/McsWorld/blob/master/dirTchInf/McsTchInf000002.last.html,
    <br>• comments on <a class="clsPreview" href="McsTchInf000000.last.html#idComment">Disqus</a>,
    <br>• twitter: <a href="https://twitter.com/synagonism">@synagonism</a>,
    <a class="clsHide" href="#idFooterP1"></a></p>
  <!--                              -->
  <p id="idMetaVersion">webpage-versions::
    <br>• version.last.dynamic: <a class="clsPreview" href="McsTchInf000002.last.html">McsTchInf000002.last.html</a>,
    <br>• version.1-0-0.2021-04-08: (0-17) <a href="../../dirMiwMcs/dirTchInf/filMcsTchInf.1-0-0.2021-04-08.html">../../dirMiwMcs/dirTchInf/filMcsTchInf.1-0-0.2021-04-08.html</a>,
    <br>• version.0-1-0.2019-12-28 draft creation,
    <a class="clsHide" href="#idMetaVersion"></a></p>
</section>

<section id="idSupport">
  <h1 id="idSupportH1">support (<a class="clsPreview" href="../../#idSupport">link</a>)</h1>
  <p></p>
</section>

<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-19285371-5', 'synagonism.net');
  ga('send', 'pageview');
</script>

<script type="module">
  import * as oMcsh from '../Mcsmgr/mMcsh.js'
</script>
</body>
</html>